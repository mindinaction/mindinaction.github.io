
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"My core interest in the human mind and brain lies in the bidirectional link between action and perception. In particular, I study how active observers select and integrate visual information and how actions orchestrate memory maintenance. In our research, we show how eye movements and accompanying shifts of attention shape what we see and what we remember—typically by setting strong spatial priorities. In a new line of research, I use adaptation to localize and dissect the mechanisms underlying causal perception. See also my personal website https://svenohl.wordpress.com.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4bb0048deaca203c43f52969e9ebf18e","permalink":"https://example.com/author/sven-ohl/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sven-ohl/","section":"authors","summary":"My core interest in the human mind and brain lies in the bidirectional link between action and perception. In particular, I study how active observers select and integrate visual information and how actions orchestrate memory maintenance.","tags":null,"title":"Sven Ohl","type":"authors"},{"authors":null,"categories":null,"content":"We are currently recruiting.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3b3a061865f77335949f7ad6efbb7be2","permalink":"https://example.com/author/open-phd-position/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/open-phd-position/","section":"authors","summary":"We are currently recruiting.","tags":null,"title":"Open PhD-position","type":"authors"},{"authors":null,"categories":null,"content":"We are currently recruiting.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"89fe01e96e081a7fcab803da0f41939f","permalink":"https://example.com/author/open-shk-position/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/open-shk-position/","section":"authors","summary":"We are currently recruiting.","tags":null,"title":"Open SHK-position","type":"authors"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://example.com/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/example/","section":"event","summary":"An example event.","tags":[],"title":"Example Event","type":"event"},{"authors":null,"categories":null,"content":"We have a website. If you are interested in studying the interplay between actions and memory, or the perception of causality, please consider joining the lab in Berlin. Watch this space for new positions over the next couple of months.\nI will be more than happy to discuss possibilities for you to join us.\n","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"74cc2cb59c4f00eeb42ad2c0e52e62ba","permalink":"https://example.com/post/24-01-01-the-website/","publishdate":"2024-01-01T00:00:00Z","relpermalink":"/post/24-01-01-the-website/","section":"post","summary":"We have a website. If you are interested in studying the interplay between actions and memory, or the perception of causality, please consider joining the lab in Berlin. Watch this space for new positions over the next couple of months.\n","tags":null,"title":"Launch of the lab website","type":"post"},{"authors":["Ohl","Rolfs"],"categories":null,"content":"","date":1703116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1703116800,"objectID":"c82bdb5339850ee211fcdbc42a93fec7","permalink":"https://example.com/publication/ohl.elife.2024/","publishdate":"2023-12-21T00:00:00Z","relpermalink":"/publication/ohl.elife.2024/","section":"publication","summary":"Detecting causal relations structures our perception of events in the world. Here, we determined whether generalized or specialized visual routines underly the perception of causality by assessing the adaptability of specific features in launching events of simple geometric shapes. After prolonged exposure to causal launch events (the adaptor) defined by a particular set of features (i.e., a particular motion direction, motion speed, or feature conjunction), observers were less likely to see causal interactions in subsequent ambiguous test events. We assessed whether this negative aftereffect transfers to test events with a new set of feature values that were not presented during adaptation. Processing in specialized (as opposed to generalized) visual routines predicts that the transfer of adaptation depends on the feature-similarity of the adaptor and the test event. We show that negative aftereffects do not transfer to unadapted launch directions. Crucially, adaptation was contingent on the causal impression in launches as demonstrated by a lack of adaptation in non-causal control events. In contrast, adaptation to launches with a particular motion speed transferred also to a different speed. Moreover, adaptation based on feature conjunctions (color and launch direction) revealed that launch direction trumps the feature identity of the object for causal perception; the adaptation transferred across colors if the test event had the same motion direction as the adaptor. In summary, visual adaptation allowed us to carve out a visual feature space underlying the perception of causality and revealed specialized visual routines that are tuned to a launch’s motion direction.","tags":null,"title":"Visual routines for detecting causal interactions are tuned to motion direction","type":"publication"},{"authors":null,"categories":null,"content":"This is the playground to test local changes.\nAnd implement different settings.\n","date":1700438400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700438400,"objectID":"585b8144115c5f114269f912f3443988","permalink":"https://example.com/extra/","publishdate":"2023-11-20T00:00:00Z","relpermalink":"/extra/","section":"","summary":"This is the playground to test local changes.\n","tags":null,"title":"Playground","type":"page"},{"authors":["Ohl","Kroell","Rolfs"],"categories":null,"content":"","date":1696118400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696118400,"objectID":"a5f4ec203d47803cfa525b1257fb0d7e","permalink":"https://example.com/publication/ohl.jepgen.2023/","publishdate":"2023-10-01T00:00:00Z","relpermalink":"/publication/ohl.jepgen.2023/","section":"publication","summary":"Visual working memory and actions are closely intertwined. Memory can guide our actions, but actions also impact what we remember. Even during memory maintenance, actions such as saccadic eye movements select content in visual working memory, resulting in better memory at locations that are congruent with the action goal as compared to incongruent locations. Here, we further substantiate the claim that saccadic eye movements are fundamentally linked to visual working memory by analyzing a large data set (\u003e 100k trials) of nine experiments (eight of them previously published). Using Bayesian hierarchical models, we demonstrate robust saccadic selection across the full range of probed saccade directions, manifesting as better memory performance at the saccade goal irrespective of its location in the visual field. By inspecting individual differences in saccadic selection, we show that saccadic selection was highly prevalent in the population. Moreover, both saccade metrics and visual working memory performance varied considerably across the visual field. Crucially, however, both idiosyncratic and systematic visual field anisotropies were not correlated between visual working memory and the oculomotor system, suggesting that they resulted from different sources (e.g., rely on separate spatial maps). In stark contrast, trial-by-trial variations in saccade metrics were strongly associated with memory performance. At any given location, shorter saccade latencies and more accurate saccades were associated with better memory performance, undergirding a robust link between action selection and visual memory.","tags":null,"title":"Saccadic selection in visual working memory is robust across the visual field and linked to saccade metrics: Evidence from nine experiments and more than 100,000 trials","type":"publication"},{"authors":["Klotzsche","Gaebler","Villringer","Sommer","Nikulin","Ohl"],"categories":null,"content":"","date":1688256000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688256000,"objectID":"771741aaf7f3ade7e813fd00134e18a5","permalink":"https://example.com/publication/klotzsche.psychophys.2023/","publishdate":"2023-07-02T00:00:00Z","relpermalink":"/publication/klotzsche.psychophys.2023/","section":"publication","summary":"Virtual reality (VR) offers a powerful tool for investigating cognitive processes, as it allows researchers to gauge behaviors and mental states in complex, yet highly controlled, scenarios. The use of VR head-mounted displays in combination with physiological measures such as EEG presents new challenges and raises the question whether established findings also generalize to a VR setup. Here, we used a VR headset to assess the spatial constraints underlying two well-established EEG correlates of visual short-term memory:the amplitude of the contralateral delay activity (CDA) and the lateralization of induced alpha power during memory retention. We tested observers' visual memory in a change detection task with bilateral stimulus arrays of either two or four items while varying the horizontal eccentricity of the memory arrays (4, 9, or 14 degrees of visual angle). The CDA amplitude differed between high and low memory load at the two smaller eccentricities, but not at the largest eccentricity. Neither memory load nor eccentricity significantly influenced the observed alpha lateralization. We further fitted time-resolved spatial filters to decode memory load from the event-related potential as well as from its time-frequency decomposition. Classification performance during the retention interval was above-chance level for both approaches and did not vary significantly across eccentricities. We conclude that commercial VR hardware can be utilized to study the CDA and lateralized alpha power, and we provide caveats for future studies targeting these EEG markers of visual memory in a VR setup.","tags":null,"title":"Visual short-term memory-related EEG components in a virtual reality setup","type":"publication"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://example.com/contact/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"Contact","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://example.com/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"https://example.com/tour/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/tour/","section":"","summary":"","tags":null,"title":"Tour","type":"landing"}]