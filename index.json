
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"My core interest in the human mind and brain lies in the bidirectional link between action and perception. In particular, I study how active observers select and integrate visual information and how actions orchestrate memory maintenance. In our research, we show how eye movements and accompanying shifts of attention shape what we see and what we remember—typically by setting strong spatial priorities. In a new line of research, I use adaptation to localize and dissect the mechanisms underlying causal perception. See also my personal website https://svenohl.wordpress.com.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4bb0048deaca203c43f52969e9ebf18e","permalink":"https://mindinaction.github.io/author/sven-ohl/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sven-ohl/","section":"authors","summary":"My core interest in the human mind and brain lies in the bidirectional link between action and perception. In particular, I study how active observers select and integrate visual information and how actions orchestrate memory maintenance.","tags":null,"title":"Sven Ohl","type":"authors"},{"authors":null,"categories":null,"content":"A fully funded 3-year PhD position (E13, 75 %) is available in the newly established Heisenberg Group (The Mind in Action Lab) of Sven Ohl at Humboldt-Universität zu Berlin, Germany. In the DFG funded project, we will study the perception of causality using psychophysics, eye-tracking and virtual reality. We will collaborate with Martin Rolfs and rolfslab.de at Humboldt-Universität zu Berlin. Preferred starting date for this position is 01 APRIL 2024, but I will also consider applications with later preferences. Please apply by 14 FEB 2024.\nThe lab’s core research areas include the interplay between action (e.g., eye movements) and visual cognition. We like to develop new psychophysics experiments in that domain and combine them with a broad range of tools including eye-tracking, high-speed projection systems, VR, EEG, ECG, and applied statistics.\nWe are seeking a motivated PhD student with a Masters degree in a relevant field (e.g., Psychology, Vision Science, Neuroscience, Computer Science, Cognitive Science, …). Solid programming skills for control of the experiments (e.g., Matlab/Psychtoolbox, Python, or Unity) and data analysis (e.g., in R) are beneficial for the project. However, these relevant skills can also be acquired and advanced during the project.\nTo apply, please send a letter that motivates your application for this particular project and your CV, as well as relevant certificates as a single pdf to: sven.ohl@hu-berlin.de.\nThe letter must include the reference number for the position you are applying for (DR/023/24)\nWe are looking forward to hearing from you, Sven Ohl\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3b3a061865f77335949f7ad6efbb7be2","permalink":"https://mindinaction.github.io/author/open-phd-position/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/open-phd-position/","section":"authors","summary":"A fully funded 3-year PhD position (E13, 75 %) is available in the newly established Heisenberg Group (The Mind in Action Lab) of Sven Ohl at Humboldt-Universität zu Berlin, Germany. In the DFG funded project, we will study the perception of causality using psychophysics, eye-tracking and virtual reality.","tags":null,"title":"Open PhD-position","type":"authors"},{"authors":null,"categories":null,"content":"We are currently recruiting.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"89fe01e96e081a7fcab803da0f41939f","permalink":"https://mindinaction.github.io/author/open-shk-position/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/open-shk-position/","section":"authors","summary":"We are currently recruiting.","tags":null,"title":"Open SHK-position","type":"authors"},{"authors":null,"categories":null,"content":"I am interested in studying context effects in perception.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"46d9eca805cd0884fa84359ddb32cafe","permalink":"https://mindinaction.github.io/author/ben-sommer/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ben-sommer/","section":"authors","summary":"I am interested in studying context effects in perception.","tags":null,"title":"Ben Sommer","type":"authors"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://mindinaction.github.io/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/example/","section":"event","summary":"An example event.","tags":[],"title":"Example Event","type":"event"},{"authors":null,"categories":null,"content":"If you are currently enrolled as a student and would like to work in our laboratory in Berlin, then this job may be of interest to you. You will support us in collecting data for psychophysical experiments and gain insights into our day-to-day research work. If this sounds interesting, please apply by 14 February.\n","date":1706745600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706745600,"objectID":"f488f1c26a52b1da6ee915b4d3ffa839","permalink":"https://mindinaction.github.io/post/24-02-01-call-for-shk/","publishdate":"2024-02-01T00:00:00Z","relpermalink":"/post/24-02-01-call-for-shk/","section":"post","summary":"If you are currently enrolled as a student and would like to work in our laboratory in Berlin, then this job may be of interest to you. You will support us in collecting data for psychophysical experiments and gain insights into our day-to-day research work. If this sounds interesting, please apply by 14 February.\n","tags":null,"title":"Apply as a student research assistant","type":"post"},{"authors":null,"categories":null,"content":"The call for our first Phd position in the lab is now online. If you would like to work on the perception of causality over the next few years, please apply by 14 FEB 2024. See https://mindinaction.github.io/author/open-phd-position/ and https://haushalt-und-personal.hu-berlin.de/de/personal/stellenausschreibungen/wiss-mitarbeiter-in-m-w-d-mit-vorauss-3-4-teilzeitbeschaeftigung-e-13-tv-l-hu-drittmittelfinanzierung-befristet-fuer-3-jahre for more information.\nWhen applying, please refer to the number DR/023/24 in your application. I am looking forward to meeting you.\n","date":1705449600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705449600,"objectID":"6c2cb9bee98362a55fac3feeab3c9c78","permalink":"https://mindinaction.github.io/post/24-01-17-call-for-phd-position/","publishdate":"2024-01-17T00:00:00Z","relpermalink":"/post/24-01-17-call-for-phd-position/","section":"post","summary":"The call for our first Phd position in the lab is now online. If you would like to work on the perception of causality over the next few years, please apply by 14 FEB 2024. See https://mindinaction.github.io/author/open-phd-position/ and https://haushalt-und-personal.hu-berlin.de/de/personal/stellenausschreibungen/wiss-mitarbeiter-in-m-w-d-mit-vorauss-3-4-teilzeitbeschaeftigung-e-13-tv-l-hu-drittmittelfinanzierung-befristet-fuer-3-jahre for more information.\n","tags":null,"title":"Call for PhD position","type":"post"},{"authors":["Rolfs","Schweitzer","Castet","Watson","Ohl"],"categories":null,"content":"","date":1704931200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704931200,"objectID":"1ad80ea23a28c7447fdbcd2ce369b8ca","permalink":"https://mindinaction.github.io/publication/rolfs.2024/","publishdate":"2024-01-11T00:00:00Z","relpermalink":"/publication/rolfs.2024/","section":"publication","summary":"Perception relies on active sampling of the environment. What part of the physical world can be sensed is limited by biophysical constraints of sensory systems, but might be further constrained by the kinematic bounds of the motor actions that acquire sensory information. We tested this fundamental idea for humans’ fastest and most frequent behavior—saccadic eye movements—which entails retinal motion that commonly escapes visual awareness. We discover that the visibility of a high-speed stimulus, presented during fixation, is predicted by the lawful sensorimotor contingencies that saccades routinely impose on the retina, reflecting even distinctive variability between observers’ movements. Our results suggest that the visual systems’ functional and implementational properties are best understood in the context of movement kinematics that impact its sensory surface.","tags":null,"title":"Lawful kinematics link eye movements to the limits of high-speed perception","type":"publication"},{"authors":["Ohl","Rolfs"],"categories":null,"content":"","date":1704844800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704844800,"objectID":"c82bdb5339850ee211fcdbc42a93fec7","permalink":"https://mindinaction.github.io/publication/ohl.elife.2024/","publishdate":"2024-01-10T00:00:00Z","relpermalink":"/publication/ohl.elife.2024/","section":"publication","summary":"Detecting causal relations structures our perception of events in the world. Here, we determined whether generalized or specialized visual routines underly the perception of causality by assessing the adaptability of specific features in launching events of simple geometric shapes. After prolonged exposure to causal launch events (the adaptor) defined by a particular set of features (i.e., a particular motion direction, motion speed, or feature conjunction), observers were less likely to see causal interactions in subsequent ambiguous test events. We assessed whether this negative aftereffect transfers to test events with a new set of feature values that were not presented during adaptation. Processing in specialized (as opposed to generalized) visual routines predicts that the transfer of adaptation depends on the feature-similarity of the adaptor and the test event. We show that negative aftereffects do not transfer to unadapted launch directions. Crucially, adaptation was contingent on the causal impression in launches as demonstrated by a lack of adaptation in non-causal control events. In contrast, adaptation to launches with a particular motion speed transferred also to a different speed. Moreover, adaptation based on feature conjunctions (color and launch direction) revealed that launch direction trumps the feature identity of the object for causal perception; the adaptation transferred across colors if the test event had the same motion direction as the adaptor. In summary, visual adaptation allowed us to carve out a visual feature space underlying the perception of causality and revealed specialized visual routines that are tuned to a launch’s motion direction.","tags":null,"title":"Visual routines for detecting causal interactions are tuned to motion direction","type":"publication"},{"authors":null,"categories":null,"content":"We have a website. If you are interested in studying the interplay between actions and memory, or the perception of causality, please consider joining the lab in Berlin. Watch this space for new positions over the next couple of months.\nI will be more than happy to discuss possibilities for you to join us.\n","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"74cc2cb59c4f00eeb42ad2c0e52e62ba","permalink":"https://mindinaction.github.io/post/24-01-01-the-website/","publishdate":"2024-01-01T00:00:00Z","relpermalink":"/post/24-01-01-the-website/","section":"post","summary":"We have a website. If you are interested in studying the interplay between actions and memory, or the perception of causality, please consider joining the lab in Berlin. Watch this space for new positions over the next couple of months.\n","tags":null,"title":"Launch of the lab website","type":"post"},{"authors":["Ohl","Kroell","Rolfs"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"a5f4ec203d47803cfa525b1257fb0d7e","permalink":"https://mindinaction.github.io/publication/ohl.jepgen.2023/","publishdate":"2024-01-01T00:00:00Z","relpermalink":"/publication/ohl.jepgen.2023/","section":"publication","summary":"Visual working memory and actions are closely intertwined. Memory can guide our actions, but actions also impact what we remember. Even during memory maintenance, actions such as saccadic eye movements select content in visual working memory, resulting in better memory at locations that are congruent with the action goal as compared to incongruent locations. Here, we further substantiate the claim that saccadic eye movements are fundamentally linked to visual working memory by analyzing a large data set (\u003e 100k trials) of nine experiments (eight of them previously published). Using Bayesian hierarchical models, we demonstrate robust saccadic selection across the full range of probed saccade directions, manifesting as better memory performance at the saccade goal irrespective of its location in the visual field. By inspecting individual differences in saccadic selection, we show that saccadic selection was highly prevalent in the population. Moreover, both saccade metrics and visual working memory performance varied considerably across the visual field. Crucially, however, both idiosyncratic and systematic visual field anisotropies were not correlated between visual working memory and the oculomotor system, suggesting that they resulted from different sources (e.g., rely on separate spatial maps). In stark contrast, trial-by-trial variations in saccade metrics were strongly associated with memory performance. At any given location, shorter saccade latencies and more accurate saccades were associated with better memory performance, undergirding a robust link between action selection and visual memory.","tags":null,"title":"Saccadic selection in visual working memory is robust across the visual field and linked to saccade metrics: Evidence from nine experiments and more than 100,000 trials","type":"publication"},{"authors":null,"categories":null,"content":"This is the playground to test local changes.\nAnd implement different settings.\n","date":1700438400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700438400,"objectID":"585b8144115c5f114269f912f3443988","permalink":"https://mindinaction.github.io/extra/","publishdate":"2023-11-20T00:00:00Z","relpermalink":"/extra/","section":"","summary":"This is the playground to test local changes.\n","tags":null,"title":"Playground","type":"page"},{"authors":["Klotzsche","Gaebler","Villringer","Sommer","Nikulin","Ohl"],"categories":null,"content":"","date":1688256000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688256000,"objectID":"771741aaf7f3ade7e813fd00134e18a5","permalink":"https://mindinaction.github.io/publication/klotzsche.psychophys.2023/","publishdate":"2023-07-02T00:00:00Z","relpermalink":"/publication/klotzsche.psychophys.2023/","section":"publication","summary":"Virtual reality (VR) offers a powerful tool for investigating cognitive processes, as it allows researchers to gauge behaviors and mental states in complex, yet highly controlled, scenarios. The use of VR head-mounted displays in combination with physiological measures such as EEG presents new challenges and raises the question whether established findings also generalize to a VR setup. Here, we used a VR headset to assess the spatial constraints underlying two well-established EEG correlates of visual short-term memory:the amplitude of the contralateral delay activity (CDA) and the lateralization of induced alpha power during memory retention. We tested observers' visual memory in a change detection task with bilateral stimulus arrays of either two or four items while varying the horizontal eccentricity of the memory arrays (4, 9, or 14 degrees of visual angle). The CDA amplitude differed between high and low memory load at the two smaller eccentricities, but not at the largest eccentricity. Neither memory load nor eccentricity significantly influenced the observed alpha lateralization. We further fitted time-resolved spatial filters to decode memory load from the event-related potential as well as from its time-frequency decomposition. Classification performance during the retention interval was above-chance level for both approaches and did not vary significantly across eccentricities. We conclude that commercial VR hardware can be utilized to study the CDA and lateralized alpha power, and we provide caveats for future studies targeting these EEG markers of visual memory in a VR setup.","tags":null,"title":"Visual short-term memory-related EEG components in a virtual reality setup","type":"publication"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://mindinaction.github.io/contact/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"Contact","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://mindinaction.github.io/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"https://mindinaction.github.io/tour/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/tour/","section":"","summary":"","tags":null,"title":"Tour","type":"landing"},{"authors":["Rolfs","Ohl"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"55c582d77ef8655b30f7bf67b85ecbb0","permalink":"https://mindinaction.github.io/publication/rolfs.bbs.2021/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/rolfs.bbs.2021/","section":"publication","summary":"In active agents, sensory and motor processes form an inevitable bond. This wedding is particularly striking for saccadic eye movements—the prime target of Shadmehr and Ahmed’s thesis—which impose frequent changes on the retinal image. Changes in movement vigor (latency and speed), therefore, will need to be accompanied by changes in visual and attentional processes. We argue that the mechanisms that control movement vigor may also enable vision to attune to changes in movement kinematics.","tags":null,"title":"Moving fast and seeing slow? The perceptual consequences of vigorous movement","type":"publication"},{"authors":["Heuer","Ohl","Rolfs"],"categories":null,"content":"","date":1588032000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588032000,"objectID":"23815f73894cd7120296d2bf3c426688","permalink":"https://mindinaction.github.io/publication/heuer.viscog.2020/","publishdate":"2020-04-28T00:00:00Z","relpermalink":"/publication/heuer.viscog.2020/","section":"publication","summary":"Perception is shaped by actions, which determine the allocation of selective attention across the visual field. Here, we review evidence that maintenance in visual working memory is similarly influenced by actions (eye or hand movements), planned and executed well after encoding. Representations that are relevant for an upcoming action – because they spatially correspond to the action goal or because they are defined along action-related feature dimensions – are automatically prioritised over action-irrelevant representations and held in a stable state. We summarise what is known about specific characteristics and mechanisms of selection-for-action in working memory, such as its temporal dynamics and spatial specificity, and delineate open questions. This newly-burgeoning area of research promotes a more functional perspective on visual working memory that emphasizes its role in action control.","tags":null,"title":"Memory for action: A functional view of selection in visual working memory","type":"publication"},{"authors":["Ohl","Rolfs"],"categories":null,"content":"","date":1581724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581724800,"objectID":"bfef6cbe87750117dd8be98fe2999baf","permalink":"https://mindinaction.github.io/publication/ohl.jvis.2020/","publishdate":"2020-02-15T00:00:00Z","relpermalink":"/publication/ohl.jvis.2020/","section":"publication","summary":"Selection for visual short-term memory (vstm) provides a basis for many cognitive functions. Saccadic eye movements sway this selection in favor of stimuli previously seen at locations congruent with their target. In three experiments, we provide converging evidence that this saccadic selection is implemented as a fundamental, inevitable selection process, rather than a top-down strategy. In particular, benefits for congruent over incongruent items were largely constant across set sizes ranging from two to eight items (Experiment 1), showing that saccadic selection imposes priorities on vstm irrespective of memory load and is effective even when only few representations need to be maintained. Moreover, a decrement in performance for incongruent items occurred reliably, whether the congruent location contained a task-relevant item or an irrelevant noise patch (Experiment 2). Finally, saccadic selection was immune to a strong manipulation of the observer's attentional priorities (Experiment 3). Given the prevalence of saccades in natural vision, our results demonstrate a fundamental and ecologically relevant selection mechanism for vstm. Saccades systematically eliminate information seen at non-target locations, while information at the saccade target remains available to recall. This simple heuristic is effective in the absence of informative cues and may incapacitate voluntary selection mechanisms that are incongruent with ongoing movement plans.","tags":null,"title":"Bold moves: Inevitable saccadic selection in visual short-term memory","type":"publication"},{"authors":["Kunzendorf","Klotzsche","Akbal","Villringer","Ohl","Gaebler"],"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"fa5545e5480b3554eba132c6e0900629","permalink":"https://mindinaction.github.io/publication/kunzendorf.psychophys.2019/","publishdate":"2019-08-01T00:00:00Z","relpermalink":"/publication/kunzendorf.psychophys.2019/","section":"publication","summary":"Perception and cognition oscillate with fluctuating bodily states. For example, visual processing has been shown to change with alternating cardiac phases. Here, we study the heartbeat’s role for active information sampling—testing whether humans implicitly act upon their environment so that relevant signals appear during preferred cardiac phases. During the encoding period of a visual memory experiment, participants clicked through a set of emotional pictures to memorize them for a later recognition test. By self-paced key press, they actively prompted the onset of short (100 ms) presented pictures. Simultaneously recorded electrocardiograms allowed us to analyze the self-initiated picture onsets relative to the heartbeat. We find that self-initiated picture onsets vary across the cardiac cycle, showing an increase during cardiac systole, while memory performance was not affected by the heartbeat. We conclude that active information sampling integrates heart-related signals, thereby extending previous findings on the association between body-brain interactions and behavior.","tags":null,"title":"Active information sampling varies across the cardiac cycle","type":"publication"},{"authors":["Ohl","Rolfs"],"categories":null,"content":"","date":1530662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530662400,"objectID":"92dfb64387e229bf33f768d1d9963347","permalink":"https://mindinaction.github.io/publication/ohl.concog.2018/","publishdate":"2018-07-04T00:00:00Z","relpermalink":"/publication/ohl.concog.2018/","section":"publication","summary":"Saccadic eye movements prioritize the memory of visual stimuli that had previously been seen at the saccade target. In two experiments, we assessed whether this influence is limited to fragile memory traces or if saccades can also affect consolidated representations in visuospatial working memory (VSWM). To interfere with fragile memory traces, we presented visual masks at different delays following the offset of a memory array and simultaneously prompted participants to generate a saccade to one location. Masking was very effective. Memory performance was lowest right after the disappearance of the memory array and gradually increased for later mask onsets. In spite of that, memory was best for stimuli congruent with the saccade target. This advantage was largest at shortest delays and then decreased over the course of a second. Insofar as only consolidated representations survive interference from masks, we conclude that saccades exert spatially selective biases on stable representations in VSWM.","tags":null,"title":"Saccadic selection of stabilized items in visuospatial working memory","type":"publication"},{"authors":["Ohl","Kuper","Rolfs"],"categories":null,"content":"","date":1510704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1510704000,"objectID":"94e31577a82106be4d3ba6919cb5b8ba","permalink":"https://mindinaction.github.io/publication/ohl.jvis.2017/","publishdate":"2017-11-15T00:00:00Z","relpermalink":"/publication/ohl.jvis.2017/","section":"publication","summary":"Saccadic eye movements cause a rapid sweep of the visual image across the retina and bring the saccade's target into high-acuity foveal vision. Even before saccade onset, visual processing is selectively prioritized at the saccade target. To determine how this presaccadic attention shift exerts its influence on visual selection, we compare the dynamics of perceptual tuning curves before movement onset at the saccade target and in the opposite hemifield. Participants monitored a 30-Hz sequence of randomly oriented gratings for a target orientation. Combining a reverse correlation technique previously used to study orientation tuning in neurons and general additive mixed modeling, we found that perceptual reports were tuned to the target orientation. The gain of orientation tuning increased markedly within the last 100 ms before saccade onset. In addition, we observed finer orientation tuning right before saccade onset. This increase in gain and tuning occurred at the saccade target location and was not observed at the incongruent location in the opposite hemifield. The present findings suggest, therefore, that presaccadic attention exerts its influence on vision in a spatially and feature-selective manner, enhancing performance and sharpening feature tuning at the future gaze location before the eyes start moving.","tags":null,"title":"Selective enhancement of orientation tuning before saccades","type":"publication"},{"authors":["Ohl","Rolfs"],"categories":null,"content":"","date":1495584000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1495584000,"objectID":"88c70c8462048402c406362f9d7ee106","permalink":"https://mindinaction.github.io/publication/ohl.bbs.2017/","publishdate":"2017-05-24T00:00:00Z","relpermalink":"/publication/ohl.bbs.2017/","section":"publication","summary":"Using fixations as the fundamental unit of visual search is an appealing gear change in a paradigm that has long dominated attention research. To truly inform theories of search, however, additional challenges must be faced, including (1) an empirically motivated definition of fixation in the presence of fixational saccades and (2) the biases and limitations of transsaccadic perception and memory.","tags":null,"title":"Chances and challenges for an active visual search perspective","type":"publication"},{"authors":["Ohl","Rolfs"],"categories":null,"content":"","date":1494806400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494806400,"objectID":"bd7a8497c0c7478e0878ed972a82349c","permalink":"https://mindinaction.github.io/publication/ohl.jeplmc.2017/","publishdate":"2017-05-15T00:00:00Z","relpermalink":"/publication/ohl.jeplmc.2017/","section":"publication","summary":"Visual short-term memory (VSTM) is a crucial repository of information when events unfold rapidly before our eyes, yet it maintains only a fraction of the sensory information encoded by the visual system. Here, we tested the hypothesis that saccadic eye movements provide a natural bottleneck for the transition of fragile content in sensory memory to VSTM. In 4 experiments, we show that saccades, planned and executed after the disappearance of a memory array, markedly bias visual memory performance. First, items that had appeared at the saccade target were more readily remembered than items that had appeared elsewhere, even though the saccade was irrelevant to the memory task (Experiment 1). Second, this influence was strongest for saccades elicited right after the disappearance of the memory array and gradually declined over the course of a second (Experiment 2). Third, the saccade stabilized memory representations. The imposed bias persisted even several seconds after saccade execution (Experiment 3). Finally, the advantage for stimuli congruent with the saccade target occurred even when that stimulus was far less likely to be probed in the memory test than any other stimulus in the array, ruling out a strategic effort of observers to memorize information presented at the saccade target (Experiment 4). Together, these results make a strong case that saccades inadvertently determine the content of VSTM, and highlight the key role of actions for the fundamental building blocks of cognition.","tags":null,"title":"Saccadic eye movements impose a natural bottleneck on visual short-term memory","type":"publication"},{"authors":["Kalogeropoulou","Jagadeesh","Ohl","Rolfs"],"categories":null,"content":"","date":1492214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492214400,"objectID":"f1cb083593742500a560c6ec9b007f4d","permalink":"https://mindinaction.github.io/publication/kalogeropoulou.pbr.2017/","publishdate":"2017-04-15T00:00:00Z","relpermalink":"/publication/kalogeropoulou.pbr.2017/","section":"publication","summary":"Many everyday tasks require prioritizing some visual features over competing ones, both during the selection from the rich sensory input and while maintaining information in visual short-term memory (VSTM). Here, we show that observers can change priorities in VSTM when, initially, they attended to a different feature. Observers reported from memory the orientation of one of two spatially interspersed groups of black and white gratings. Using colored pre-cues (presented before stimulus onset) and retro-cues (presented after stimulus offset) predicting the to-be-reported group, we manipulated observers’ feature priorities independently during stimulus encoding and maintenance, respectively. Valid pre-cues reliably increased observers’ performance (reduced guessing, increased report precision) as compared to neutral ones; invalid pre-cues had the opposite effect. Valid retro-cues also consistently improved performance (by reducing random guesses), even if the unexpected group suddenly became relevant (invalid-valid condition). Thus, feature-based attention can reshape priorities in VSTM protecting information that would otherwise be forgotten.","tags":null,"title":"Setting and changing feature priorities in Visual Short-Term Memory","type":"publication"},{"authors":["Cassanello","Ohl","Rolfs"],"categories":null,"content":"","date":1470009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470009600,"objectID":"a91ce5fdcd1283ec04572430f6a87cdc","permalink":"https://mindinaction.github.io/publication/cassanelle.jneurophys.2016/","publishdate":"2016-08-01T00:00:00Z","relpermalink":"/publication/cassanelle.jneurophys.2016/","section":"publication","summary":"Saccadic adaptation maintains the correct mapping between eye movements and their targets, yet the dynamics of saccadic gain changes in the presence of systematically varying disturbances has not been extensively studied. Here we assessed changes in the gain of saccade amplitudes induced by continuous and periodic postsaccadic visual feedback. Observers made saccades following a sequence of target steps either along the horizontal meridian (Two-way adaptation) or with unconstrained saccade directions (Global adaptation). An intrasaccadic step—following a sinusoidal variation as a function of the trial number (with 3 different frequencies tested in separate blocks)—consistently displaced the target along its vector. The oculomotor system responded to the resulting feedback error by modifying saccade amplitudes in a periodic fashion with similar frequency of variation but lagging the disturbance by a few tens of trials. This periodic response was superimposed on a drift toward stronger hypometria with similar asymptotes and decay rates across stimulus conditions. The magnitude of the periodic response decreased with increasing frequency and was smaller and more delayed for Global than Two-way adaptation. These results suggest that—in addition to the well-characterized return-to-baseline response observed in protocols using constant visual feedback—the oculomotor system attempts to minimize the feedback error by integrating its variation across trials. This process resembles a convolution with an internal response function, whose structure would be determined by coefficients of the learning model. Our protocol reveals this fast learning process in single short experimental sessions, qualifying it for the study of sensorimotor learning in health and disease.","tags":null,"title":"Saccadic adaptation to a systematically varying disturbance","type":"publication"},{"authors":["Ohl","Kliegl"],"categories":null,"content":"","date":1468540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1468540800,"objectID":"a3ddfadb32bbf61fd33800a8568edfb3","permalink":"https://mindinaction.github.io/publication/ohl.visres.2016/","publishdate":"2016-07-15T00:00:00Z","relpermalink":"/publication/ohl.visres.2016/","section":"publication","summary":"Saccadic eye movements are frequently followed by smaller secondary saccades which are generally assumed to correct for the error in primary saccade landing position. However, secondary saccades can also occur after accurate primary saccades and they are often as small as microsaccades, therefore raising the need to further scrutinize the processes involved in secondary saccade generation. Following up a previous study, we analyzed secondary saccades using rate analysis which allows us to quantify experimental effects as shifts in distributions, therefore going beyond comparisons of mean differences. We use Aalen’s additive hazards model to delineate the time course of key influences on the secondary saccade rate. In addition to the established effect of primary saccade error, we observed a time-varying influence of under- vs. overshooting – with a higher risk of generating secondary saccades following undershoots. Moreover, increasing target eccentricity influenced the programming of secondary saccades, therefore demonstrating that error-unrelated variables co-determine secondary saccade programs. Our results provide new insights into the generative mechanisms of small saccades during postsaccadic fixation that need to be accounted for by secondary saccade models.","tags":null,"title":"Revealing the time course of signals influencing the generation of secondary saccades using Aalen’s additive hazards model","type":"publication"},{"authors":["Ohl","Wohltat","Kliegl","Pollatos","Engbert"],"categories":null,"content":"","date":1453852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1453852800,"objectID":"a1068f9220dcc77324a89cca12ecb859","permalink":"https://mindinaction.github.io/publication/ohl.jn.2016/","publishdate":"2016-01-27T00:00:00Z","relpermalink":"/publication/ohl.jn.2016/","section":"publication","summary":"During visual fixation, the eye generates microsaccades and slower components of fixational eye movements that are part of the visual processing strategy in humans. Here, we show that ongoing heartbeat is coupled to temporal rate variations in the generation of microsaccades. Using coregistration of eye recording and ECG in humans, we tested the hypothesis that microsaccade onsets are coupled to the relative phase of the R-R intervals in heartbeats. We observed significantly more microsaccades during the early phase after the R peak in the ECG. This form of coupling between heartbeat and eye movements was substantiated by the additional finding of a coupling between heart phase and motion activity in slow fixational eye movements; i.e., retinal image slip caused by physiological drift. Our findings therefore demonstrate a coupling of the oculomotor system and ongoing heartbeat, which provides further evidence for bodily influences on visuomotor functioning.","tags":null,"title":"Microsaccades are coupled to heartbeat","type":"publication"}]