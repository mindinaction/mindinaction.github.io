
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"My core interest in the human mind and brain lies in the bidirectional link between action and perception. In particular, I study how active observers select and integrate visual information and how actions orchestrate memory maintenance. In our research, we show how eye movements and accompanying shifts of attention shape what we see and what we remember—typically by setting strong spatial priorities. In a new line of research, I use adaptation to localize and dissect the mechanisms underlying causal perception. See also my personal website https://svenohl.wordpress.com.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"4bb0048deaca203c43f52969e9ebf18e","permalink":"https://mindinaction.github.io/author/sven-ohl/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sven-ohl/","section":"authors","summary":"My core interest in the human mind and brain lies in the bidirectional link between action and perception. In particular, I study how active observers select and integrate visual information and how actions orchestrate memory maintenance.","tags":null,"title":"Sven Ohl","type":"authors"},{"authors":null,"categories":null,"content":"Hi! I’m Laura, PhD candidate in MIAlab. After completing my BSc in Cognitive AI and my MSc in Cognitive Neuroscience at Utrecht University (NL), I am excited to be part of MIAlab. My core topic is the Perception of Causality. I am investigating the role of elementary causality detectors in the early visual system for detecting causal interactions. To this end, I use visual adaptation protocols. Outside of the lab, you might catch me doing sports, improving my German, or eating pickles.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"26a5881add99682606e52e90a6476955","permalink":"https://mindinaction.github.io/author/laura-van-zantwijk/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/laura-van-zantwijk/","section":"authors","summary":"Hi! I’m Laura, PhD candidate in MIAlab. After completing my BSc in Cognitive AI and my MSc in Cognitive Neuroscience at Utrecht University (NL), I am excited to be part of MIAlab.","tags":null,"title":"Laura van Zantwijk","type":"authors"},{"authors":null,"categories":null,"content":"Inchara is interested in visual cognition and aims to investigate the impact of actions on perception and working memory. She is also interested in investigating feature-based attention in the active observer. Inchara joined the Berlin School of Mind and Brain, the mialab and rolfslab in October 2024 for her doctorate after completing a master’s in cognitive science from the Indian Institute of Technology, Gandhinagar.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"94e904f800d8d038c0fdd1983a472dbc","permalink":"https://mindinaction.github.io/author/inchara-manjunatha/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/inchara-manjunatha/","section":"authors","summary":"Inchara is interested in visual cognition and aims to investigate the impact of actions on perception and working memory. She is also interested in investigating feature-based attention in the active observer.","tags":null,"title":"Inchara Manjunatha","type":"authors"},{"authors":null,"categories":null,"content":"Siri is currently studying Psychology at Humboldt-Universität zu Berlin and is writing her bachelor’s thesis on the influence of body signals on visual perception. Her interest in vision and neuroscience grew through lectures and seminars, and she is now eager to gain hands-on experience in this area. She is also looking forward to learning more about scientific practices in general.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"0426998f1b096c5eceecfcb80d7a2586","permalink":"https://mindinaction.github.io/author/siri-tappesser/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/siri-tappesser/","section":"authors","summary":"Siri is currently studying Psychology at Humboldt-Universität zu Berlin and is writing her bachelor’s thesis on the influence of body signals on visual perception. Her interest in vision and neuroscience grew through lectures and seminars, and she is now eager to gain hands-on experience in this area.","tags":null,"title":"Siri Tappesser","type":"authors"},{"authors":null,"categories":null,"content":"Ben is a student in the M.Sc. Psychology at HU Berlin. He is interested in all things perception and cognition, especially causality and reasoning. Ben seeks to understand the underlying process of finding good moves in chess, so he can blunder less.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"46d9eca805cd0884fa84359ddb32cafe","permalink":"https://mindinaction.github.io/author/ben-sommer/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ben-sommer/","section":"authors","summary":"Ben is a student in the M.Sc. Psychology at HU Berlin. He is interested in all things perception and cognition, especially causality and reasoning. Ben seeks to understand the underlying process of finding good moves in chess, so he can blunder less.","tags":null,"title":"Ben Sommer","type":"authors"},{"authors":null,"categories":null,"content":"My name is Gamze, and I am a master’s student in Neuroscience and Cognition as well as Neuropsychology at Utrecht University, with a BSc in Psychology. My research interests lie in understanding how vision and eye movements interact with memory and attention. I am excited to be part of MIAlab and look forward to contributing to its projects and collaborations!\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"5ed23555079b94039dd195b4a3597955","permalink":"https://mindinaction.github.io/author/gamze-kahyaoglu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/gamze-kahyaoglu/","section":"authors","summary":"My name is Gamze, and I am a master’s student in Neuroscience and Cognition as well as Neuropsychology at Utrecht University, with a BSc in Psychology. My research interests lie in understanding how vision and eye movements interact with memory and attention.","tags":null,"title":"Gamze Kahyaoglu","type":"authors"},{"authors":null,"categories":null,"content":"Laura is currently studying Psychology at Humboldt-Universität zu Berlin and she is writing her bachelor‘s thesis on the perception of causality. Visual perception and adaptation caught her eye in the beginning of her studies already. Now she is excited to put her interests into action and collect eye-tracking experience in the lab. By doing so she hopes to deepen her understanding of perceived causality.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"7977ec19b1734cd618b588ebf029af7f","permalink":"https://mindinaction.github.io/author/laura-ackermann/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/laura-ackermann/","section":"authors","summary":"Laura is currently studying Psychology at Humboldt-Universität zu Berlin and she is writing her bachelor‘s thesis on the perception of causality. Visual perception and adaptation caught her eye in the beginning of her studies already.","tags":null,"title":"Laura Ackermann","type":"authors"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://mindinaction.github.io/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/event/example/","section":"event","summary":"An example event.","tags":[],"title":"Example Event","type":"event"},{"authors":["Sommer","Rolfs","Ohl"],"categories":null,"content":"","date":1758412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1758412800,"objectID":"3a26aa454260cdef194f101a62406adf","permalink":"https://mindinaction.github.io/publication/sro.2025/","publishdate":"2025-09-21T00:00:00Z","relpermalink":"/publication/sro.2025/","section":"publication","summary":"Results from psychophysical studies using visual adaptation suggest that launch detectors in the visual system underlie the perception of causality in simple visual events. These detectors respond to events in which one stimulus collides with another stimulus (i.e., a launch), and do not respond to events where one stimulus passes over another (i.e., a pass). Prolonged visual adaptation to launches significantly reduces observers’ propensity to see causal launches at the same retinotopic location. This finding could be taken to indicate that launch detectors are necessary for the local detection of causal launches. However, contextual events—that are spatially separated from the test event location—shift observers' perception of a causal relation in the direction of the type of contextual event (Scholl \u0026 Nakayama, 2002), providing evidence for spatial integration beyond a specific retinotopic location. Here, we used visual adaptation as a tool to investigate whether the contextual influence on causal perception relies on local launch detectors. Before and after adaptation, we determined the proportion of reported launches in ambiguous test events in the presence of no context, launch context, and pass context events. We hypothesized that if the contextual influence relies on (unadapted) local launch detectors, then visual adaptation should affect the contextual influence on causal perception. Before adaptation, a launch-context event increased the proportion of reported launches (while a pass context event decreased it). Visual adaptation to launches significantly decreased the proportion of reported launches in no-context trials, but did not affect perceptual reports in no-context trials. In fact, contextual influences, expressed relative to no-context trials, emerged strongly after adaptation. This result suggests that context effects override strong negative aftereffects from adaptation, indicating that contextual influences operate at a level that bypasses the local launch detector at the adapted location.","tags":null,"title":"Putting causality into context: Causal capture escapes the visual adaptation of causality","type":"publication"},{"authors":["Klanke","Ohl","Rolfs"],"categories":null,"content":"","date":1758326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1758326400,"objectID":"6341597f572891f76b76dffa1fb7e734","permalink":"https://mindinaction.github.io/publication/klanke.2025c/","publishdate":"2025-09-20T00:00:00Z","relpermalink":"/publication/klanke.2025c/","section":"publication","summary":"","tags":null,"title":"In pursuit of saccade awareness: Limited control and minimal conscious access to catch-up saccades during smooth pursuit eye movements","type":"publication"},{"authors":["Klanke","Ohl","Rolfs"],"categories":null,"content":"","date":1758240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1758240000,"objectID":"88162b85e8058cfd9b65696744da9b0b","permalink":"https://mindinaction.github.io/publication/klanke.2025b/","publishdate":"2025-09-19T00:00:00Z","relpermalink":"/publication/klanke.2025b/","section":"publication","summary":"Feeling of agency (FoA)—the experience of controlling one's actions and their outcomes—has been widely studied for bodily movements. Here, we investigated if microsaccades—small ballistic eye movements—are equally characterized by FoA and if intention mediates this sense of control. We measured FoA via intentional binding, a perceived compression between an action and its effect. In our experiments, we presented a vertically oriented grating, rendered invisible during stable fixation by a rapid temporal phase shift (\u003e60 Hz) that became visible when its retinal motion was slowed down by a microsaccade (active condition). The stimulus was embedded in a clock face and observers reported perceived stimulus timing in each trial. Perceived timing of microsaccade-contingent stimulus perception was compared to the replay of a previous microsaccade's retinal consequence (replay condition). Trials without a stimulus were included as a control. To examine the role of intention, we tested this paradigm across two experiments in which observers were either instructed to saccade (intended microsaccades) or fixate (unintended microsaccades). In Experiment 2, no instruction was administered such that any microsaccades were considered spontaneous. Microsaccades—either actively generated or replayed—consistently rendered the stimulus highly visible compared to trials without such movements—provided microsaccade direction and peak velocity aligned with the stimulus's motion. Temporal estimates did not differ between the active and replay conditions for any microsaccade type. This result suggests the absence of temporal binding between eye movements and their sensory consequences, and that intention does not facilitate FoA for small eye movements.","tags":null,"title":"Microsaccades do not give rise to a conscious feeling of agency for their sensorimotor consequences in visual perception","type":"publication"},{"authors":null,"categories":null,"content":"An exciting science summer is coming to an end. Laura presented her current experiments at the summer school in Tübingen and deepened her knowledge of statistics at the summer school “Statistical Methods for Linguistics and Psychology” in Potsdam. Inchara presented her work on ensemble perception at ECVP in Mainz while Ben had the chance to learn more about visual perception at a summer school in Pisa.\n","date":1757980800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1757980800,"objectID":"4a785d151aa999ecef152b9b64f8c78c","permalink":"https://mindinaction.github.io/post/25-09-16-summerend/","publishdate":"2025-09-16T00:00:00Z","relpermalink":"/post/25-09-16-summerend/","section":"post","summary":"An exciting science summer is coming to an end. Laura presented her current experiments at the summer school in Tübingen and deepened her knowledge of statistics at the summer school “Statistical Methods for Linguistics and Psychology” in Potsdam. Inchara presented her work on ensemble perception at ECVP in Mainz while Ben had the chance to learn more about visual perception at a summer school in Pisa.\n","tags":null,"title":"Summer comes to an end","type":"post"},{"authors":null,"categories":null,"content":"This paper on the visibility of saccade-like motion has been long in the making and is finally out. In a tour de force this paper shows that the perceptual thresholds for high-speed motion perception during fixation can be predicted based on the lawful kinematics of saccadic eye movements. Check out the paper just published in Nature Communications https://www.nature.com/articles/s41467-025-58659-9 and the press release https://www.scienceofintelligence.de/too-fast-to-see-eye-movements-predict-speed-limits-in-perception/.\n","date":1746662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1746662400,"objectID":"f48362e46d38ad639e3fd191b359c8f3","permalink":"https://mindinaction.github.io/post/25-05-08-natcomm/","publishdate":"2025-05-08T00:00:00Z","relpermalink":"/post/25-05-08-natcomm/","section":"post","summary":"This paper on the visibility of saccade-like motion has been long in the making and is finally out. In a tour de force this paper shows that the perceptual thresholds for high-speed motion perception during fixation can be predicted based on the lawful kinematics of saccadic eye movements. Check out the paper just published in Nature Communications https://www.nature.com/articles/s41467-025-58659-9 and the press release https://www.scienceofintelligence.de/too-fast-to-see-eye-movements-predict-speed-limits-in-perception/.\n","tags":null,"title":"New paper in Nature Communications and press release","type":"post"},{"authors":["Klanke","Ohl","Rolfs"],"categories":null,"content":"","date":1746316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1746316800,"objectID":"56059b9d2169b0f82e971a4935888c6b","permalink":"https://mindinaction.github.io/publication/klanke.2025a/","publishdate":"2025-05-04T00:00:00Z","relpermalink":"/publication/klanke.2025a/","section":"publication","summary":"Microsaccades are tiny eye movements that are thought to occur spontaneously and without awareness but can also be intentionally controlled with high precision. We used these tiny visual actions to investigate how intention modulates sensorimotor awareness by directly comparing intended, unintended, and spontaneous microsaccades. In addition, we dissociated the effects of action intention and the actions' visual consequences on awareness. In 80\\% of all trials, we presented a stimulus at high temporal frequency rendering it invisible during stable fixation. Critically, the stimulus became visible when a microsaccade in the same direction caused it to slow down on the retina (generated microsaccade condition; 40\\% of trials) or when the microsaccades' visual consequence was replayed (replayed microsaccade condition; 40\\% of trials). Participants reported whether they perceived the stimulus (visual sensitivity), whether they believed they had made a microsaccade (microsaccade sensitivity), and their level of confidence that their eye movement behavior was linked to their perception (causality assignment). Visual sensitivity was high for both, generated and replayed microsaccades and comparable for intended, unintended, and spontaneous eye movements. Microsaccade sensitivity, however, was low for spontaneous microsaccades, but heightened for both intended and unintended eye movements, showing that the intention to saccade or fixate enhances awareness of otherwise undetected eye movements. Visual consequences failed to aid eye movement awareness, and confidence ratings revealed a poor understanding of a causal relationship between eye movement and sensory consequence. These findings highlight the functional relevance of intention in sensorimotor awareness at the smallest scale of visual actions.","tags":null,"title":"Sensorimotor awareness requires intention: Evidence from minuscule eye movements","type":"publication"},{"authors":null,"categories":null,"content":"We have been to our first retreat in beautiful Forsthaus Tornow with good science, delicious food from great cooking teams, time to talk and lots of fun with a great group of people. [featured photo by Wiebke]\ngroup picture of rolfslab and mialab [photo by Caro] mentoring walk [photo by Inchara] the retreat location [photo by Siri] ","date":1744848000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1744848000,"objectID":"d27b8b78656d388d6796590fd9cb5fdd","permalink":"https://mindinaction.github.io/post/25-04-17-retreat/","publishdate":"2025-04-17T00:00:00Z","relpermalink":"/post/25-04-17-retreat/","section":"post","summary":"We have been to our first retreat in beautiful Forsthaus Tornow with good science, delicious food from great cooking teams, time to talk and lots of fun with a great group of people. [featured photo by Wiebke]\n","tags":null,"title":"Joint retreat of rolfslab and mialab","type":"post"},{"authors":null,"categories":null,"content":"Ben, Martin and Sven have a new preprint on causal capture. In their study, they pitted visual adaptation against contextual influences on causal perception and found that contextual influences escaped the strong influence of visual adaptation. Congratulations to Ben for submitting his first manuscript. For more information, see https://www.biorxiv.org/content/10.1101/2025.04.10.648104v1.\n","date":1744243200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1744243200,"objectID":"1f03fb34530eeae5622dd55c586ce8ac","permalink":"https://mindinaction.github.io/post/25-04-10-preprint-capture/","publishdate":"2025-04-10T00:00:00Z","relpermalink":"/post/25-04-10-preprint-capture/","section":"post","summary":"Ben, Martin and Sven have a new preprint on causal capture. In their study, they pitted visual adaptation against contextual influences on causal perception and found that contextual influences escaped the strong influence of visual adaptation. Congratulations to Ben for submitting his first manuscript. For more information, see https://www.biorxiv.org/content/10.1101/2025.04.10.648104v1.\n","tags":null,"title":"New preprint on causal capture","type":"post"},{"authors":["Rolfs","Schweitzer","Castet","Watson","Ohl"],"categories":null,"content":"","date":1744070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1744070400,"objectID":"98e24fc56130a52dd3cacda349a35a31","permalink":"https://mindinaction.github.io/publication/rolfs.natcomm.2025/","publishdate":"2025-04-08T00:00:00Z","relpermalink":"/publication/rolfs.natcomm.2025/","section":"publication","summary":"Perception relies on active sampling of the environment. What part of the physical world can be sensed is limited by biophysical constraints of sensory systems, but might be further constrained by the kinematic bounds of the motor actions that acquire sensory information. We tested this fundamental idea for humans’ fastest and most frequent behavior—saccadic eye movements—which entails retinal motion that commonly escapes visual awareness. We discover that the visibility of a high-speed stimulus, presented during fixation, is predicted by the lawful sensorimotor contingencies that saccades routinely impose on the retina, reflecting even distinctive variability between observers’ movements. Our results suggest that the visual systems’ functional and implementational properties are best understood in the context of movement kinematics that impact its sensory surface.","tags":null,"title":"Lawful kinematics link eye movements to the limits of high-speed perception","type":"publication"},{"authors":null,"categories":null,"content":"Sven and Martin published their paper on the directional tuning of the perception of causality at eLife. For more details see https://doi.org/10.7554/eLife.93454.3\n","date":1743724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1743724800,"objectID":"cd2be8a95e528610fe1d5a5e4d30f56e","permalink":"https://mindinaction.github.io/post/25-04-03-paper-elife/","publishdate":"2025-04-04T00:00:00Z","relpermalink":"/post/25-04-03-paper-elife/","section":"post","summary":"Sven and Martin published their paper on the directional tuning of the perception of causality at eLife. For more details see https://doi.org/10.7554/eLife.93454.3\n","tags":null,"title":"New paper in eLife on the perception of causality","type":"post"},{"authors":["Ohl","Rolfs"],"categories":null,"content":"","date":1743638400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1743638400,"objectID":"c81c7627c2defbf71029fe3d1a5e3c1a","permalink":"https://mindinaction.github.io/publication/ohl.elife.2025/","publishdate":"2025-04-03T00:00:00Z","relpermalink":"/publication/ohl.elife.2025/","section":"publication","summary":"Detecting causal relations structures our perception of events in the world. Here, we determined for visual interactions whether generalized (i.e. feature-invariant) or specialized (i.e. feature-selective) visual routines underlie the perception of causality. To this end, we applied a visual adaptation protocol to assess the adaptability of specific features in classical launching events of simple geometric shapes. We asked observers to report whether they observed a launch or a pass in ambiguous test events (i.e. the overlap between two discs varied from trial to trial). After prolonged exposure to causal launch events (the adaptor) defined by a particular set of features (i.e. a particular motion direction, motion speed, or feature conjunction), observers were less likely to see causal launches in subsequent ambiguous test events than before adaptation. Crucially, adaptation was contingent on the causal impression in launches as demonstrated by a lack of adaptation in non-causal control events. We assessed whether this negative aftereffect transfers to test events with a new set of feature values that were not presented during adaptation. Processing in specialized (as opposed to generalized) visual routines predicts that the transfer of visual adaptation depends on the feature similarity of the adaptor and the test event. We show that the negative aftereffects do not transfer to unadapted launch directions but do transfer to launch events of different speeds. Finally, we used colored discs to assign distinct feature-based identities to the launching and the launched stimulus. We found that the adaptation transferred across colors if the test event had the same motion direction as the adaptor. In summary, visual adaptation allowed us to carve out a visual feature space underlying the perception of causality and revealed specialized visual routines that are tuned to a launch’s motion direction.","tags":null,"title":"Visual routines for detecting causal interactions are tuned to motion direction","type":"publication"},{"authors":null,"categories":null,"content":"The MIAlab is on the way to its first conference. We will be represented in Frankfurt at the TeaP with two posters and a talk. Get in touch with us if you are interested in the perception of causality or want to hear more about the influence of saccadic eye movements on visual memory.\nOur slots:\n11 March at 3:00 pm The Spatial Specificity and Recovery of Visual Adaptation in Causal Perception (Poster by Laura)\n12 March at 8:30 am Saccadic selection in vision and memory (Talk by Sven)\n12 March at 3:00 pm Context events bypass the influence of visual adaptation on the perception of causality (Poster by Ben)\n","date":1741132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1741132800,"objectID":"4c26947bef1f9d8e267744dba6743b52","permalink":"https://mindinaction.github.io/post/25-03-05-teap/","publishdate":"2025-03-05T00:00:00Z","relpermalink":"/post/25-03-05-teap/","section":"post","summary":"The MIAlab is on the way to its first conference. We will be represented in Frankfurt at the TeaP with two posters and a talk. Get in touch with us if you are interested in the perception of causality or want to hear more about the influence of saccadic eye movements on visual memory.\n","tags":null,"title":"MIAlab at TeaP in Frankfurt","type":"post"},{"authors":null,"categories":null,"content":"","date":1740614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1740614400,"objectID":"549195757b974f585aaa534f03e476cd","permalink":"https://mindinaction.github.io/demos/","publishdate":"2025-02-27T00:00:00Z","relpermalink":"/demos/","section":"","summary":"","tags":null,"title":"Demos","type":"landing"},{"authors":null,"categories":null,"content":"I am so happy to welcome Inchara to Berlin. She received a scholarship from the Berlin School of Mind and Brain to pursue her PhD on the interplay between actions, perception and memory.\n","date":1728950400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1728950400,"objectID":"8675ede6c3ca84374240c26ddfefce25","permalink":"https://mindinaction.github.io/post/24-10-15-october/","publishdate":"2024-10-15T00:00:00Z","relpermalink":"/post/24-10-15-october/","section":"post","summary":"I am so happy to welcome Inchara to Berlin. She received a scholarship from the Berlin School of Mind and Brain to pursue her PhD on the interplay between actions, perception and memory.\n","tags":null,"title":"Inchara joins rolfslab and mialab","type":"post"},{"authors":null,"categories":null,"content":"If you divide the lab year roughly into presenting science vs. creating science, then September is the month when we all come back to our labs and get busy tinkering, implementing and piloting new ideas. We’ve spent the last few weeks doing just that and are still getting new input through our regular Reading Club, which everyone actively attends. Our team is now almost complete for the next few months (but wait for the next post) and I am happy to work with such a wonderful team that is highly motivated to do good science.\n","date":1726358400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1726358400,"objectID":"baa41d032eb1cd6e4f706df257341ae8","permalink":"https://mindinaction.github.io/post/24-09-15-september/","publishdate":"2024-09-15T00:00:00Z","relpermalink":"/post/24-09-15-september/","section":"post","summary":"If you divide the lab year roughly into presenting science vs. creating science, then September is the month when we all come back to our labs and get busy tinkering, implementing and piloting new ideas. We’ve spent the last few weeks doing just that and are still getting new input through our regular Reading Club, which everyone actively attends. Our team is now almost complete for the next few months (but wait for the next post) and I am happy to work with such a wonderful team that is highly motivated to do good science.\n","tags":null,"title":"September outlook","type":"post"},{"authors":null,"categories":null,"content":"We are very happy to welcome Laura van Zantwijk as a new PhD student in the MIAlab. Laura did her Master in Utrecht and has already contributed to many successful research projects on active perception. Welcome to Berlin Laura. We are so happy to have you here.\n","date":1722470400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1722470400,"objectID":"77b25e729ae525b6057cb794554bef8f","permalink":"https://mindinaction.github.io/post/24-08-01-laura/","publishdate":"2024-08-01T00:00:00Z","relpermalink":"/post/24-08-01-laura/","section":"post","summary":"We are very happy to welcome Laura van Zantwijk as a new PhD student in the MIAlab. Laura did her Master in Utrecht and has already contributed to many successful research projects on active perception. Welcome to Berlin Laura. We are so happy to have you here.\n","tags":null,"title":"Welcome to the lab Laura","type":"post"},{"authors":null,"categories":null,"content":"We participated at the spontaneous RIPE workshop in Berlin. What a great opportunity to learn more about relations from so many smart people. Hopefully, this workshop will take place again next year.\n","date":1721606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1721606400,"objectID":"fbbe42e6ec1032d49f6f919f12d36358","permalink":"https://mindinaction.github.io/post/24-07-22-ripe/","publishdate":"2024-07-22T00:00:00Z","relpermalink":"/post/24-07-22-ripe/","section":"post","summary":"We participated at the spontaneous RIPE workshop in Berlin. What a great opportunity to learn more about relations from so many smart people. Hopefully, this workshop will take place again next year.\n","tags":null,"title":"Workshop on causality and spatial relations in Berlin","type":"post"},{"authors":null,"categories":null,"content":"I am so incredibly happy that this preprint on sensorimotor awareness with Jan Klanke as first author is available on biorxiv. Jan has created a wonderful new paradigm to measure microsaccade sensitivity. There are so many exciting methodological finesses in the study that together highlight the role of intention in sensorimotor awareness. See more here https://doi.org/10.1101/2024.07.02.601661\n","date":1715731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715731200,"objectID":"71600462bb0cb87891ac32c1b9c6ea51","permalink":"https://mindinaction.github.io/post/24-07-03-preprintjan/","publishdate":"2024-05-15T00:00:00Z","relpermalink":"/post/24-07-03-preprintjan/","section":"post","summary":"I am so incredibly happy that this preprint on sensorimotor awareness with Jan Klanke as first author is available on biorxiv. Jan has created a wonderful new paradigm to measure microsaccade sensitivity. There are so many exciting methodological finesses in the study that together highlight the role of intention in sensorimotor awareness. See more here https://doi.org/10.1101/2024.07.02.601661\n","tags":null,"title":"New preprint on sensorimotor awareness","type":"post"},{"authors":null,"categories":null,"content":"One of the annual highlights in our research calendar is just around the corner. The MIAlab is flying to VSS. Sven will be giving a talk on Saturday with the title “What Newton did not know about Newton’s cradle: Separating visual routines for cause and effect” in the talk session “Perception of Relations, Intuitive Physics.” A lot of other cool talks are in the same session and we are very excited.\n","date":1715731200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1715731200,"objectID":"6733aca94dbc782d01b7775cdf002add","permalink":"https://mindinaction.github.io/post/24-05-15-vss/","publishdate":"2024-05-15T00:00:00Z","relpermalink":"/post/24-05-15-vss/","section":"post","summary":"One of the annual highlights in our research calendar is just around the corner. The MIAlab is flying to VSS. Sven will be giving a talk on Saturday with the title “What Newton did not know about Newton’s cradle: Separating visual routines for cause and effect” in the talk session “Perception of Relations, Intuitive Physics.” A lot of other cool talks are in the same session and we are very excited.\n","tags":null,"title":"The MIAlab at VSS","type":"post"},{"authors":null,"categories":null,"content":"We are delighted that Siri is now starting as a student assistant in the lab. She will be a great help to us in collecting data and we are already looking forward to programming new stimuli together with her. Siri is now officially the first lab member in our still young lab. Welcome Siri!\n","date":1714521600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1714521600,"objectID":"d8d8f7b14b36178fe0c852d099733e97","permalink":"https://mindinaction.github.io/post/24-05-01-siri/","publishdate":"2024-05-01T00:00:00Z","relpermalink":"/post/24-05-01-siri/","section":"post","summary":"We are delighted that Siri is now starting as a student assistant in the lab. She will be a great help to us in collecting data and we are already looking forward to programming new stimuli together with her. Siri is now officially the first lab member in our still young lab. Welcome Siri!\n","tags":null,"title":"Welcome to Siri in the MIAlab","type":"post"},{"authors":null,"categories":null,"content":"We were in Oxford for a few days after being invited by Dejan Draschkow and his lab for a workshop on combining eye tracking and EEG in virtual reality. Felix Klotzsche gave a wonderful introduction, motivating but also highlighting some important considerations when using VR as a tool for cognitive neuroscience. On the last day, we had the pleasure of presenting our memory studies using eye movements, EEG and VR at the BEACON seminar. Thanks to our host we had the best time in Oxford.\n","date":1708300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1708300800,"objectID":"ec468e2916835543e8e7b89a7aa4bfb7","permalink":"https://mindinaction.github.io/post/24-02-01-oxford/","publishdate":"2024-02-19T00:00:00Z","relpermalink":"/post/24-02-01-oxford/","section":"post","summary":"We were in Oxford for a few days after being invited by Dejan Draschkow and his lab for a workshop on combining eye tracking and EEG in virtual reality. Felix Klotzsche gave a wonderful introduction, motivating but also highlighting some important considerations when using VR as a tool for cognitive neuroscience. On the last day, we had the pleasure of presenting our memory studies using eye movements, EEG and VR at the BEACON seminar. Thanks to our host we had the best time in Oxford.\n","tags":null,"title":"Lab visit in Oxford","type":"post"},{"authors":null,"categories":null,"content":"If you are currently enrolled as a student and would like to work in our laboratory in Berlin, then this job may be of interest to you. You will support us in collecting data for psychophysical experiments and gain insights into our day-to-day research work. If this sounds interesting, please apply by 14 February.\n","date":1706745600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1706745600,"objectID":"f488f1c26a52b1da6ee915b4d3ffa839","permalink":"https://mindinaction.github.io/post/24-02-01-call-for-shk/","publishdate":"2024-02-01T00:00:00Z","relpermalink":"/post/24-02-01-call-for-shk/","section":"post","summary":"If you are currently enrolled as a student and would like to work in our laboratory in Berlin, then this job may be of interest to you. You will support us in collecting data for psychophysical experiments and gain insights into our day-to-day research work. If this sounds interesting, please apply by 14 February.\n","tags":null,"title":"Apply as a student research assistant","type":"post"},{"authors":null,"categories":null,"content":"The call for our first Phd position in the lab is now online. If you would like to work on the perception of causality over the next few years, please apply by 14 FEB 2024. See https://mindinaction.github.io/author/open-phd-position/ and https://haushalt-und-personal.hu-berlin.de/de/personal/stellenausschreibungen/wiss-mitarbeiter-in-m-w-d-mit-vorauss-3-4-teilzeitbeschaeftigung-e-13-tv-l-hu-drittmittelfinanzierung-befristet-fuer-3-jahre for more information.\nWhen applying, please refer to the number DR/023/24 in your application. I am looking forward to meeting you.\n","date":1705449600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1705449600,"objectID":"6c2cb9bee98362a55fac3feeab3c9c78","permalink":"https://mindinaction.github.io/post/24-01-17-call-for-phd-position/","publishdate":"2024-01-17T00:00:00Z","relpermalink":"/post/24-01-17-call-for-phd-position/","section":"post","summary":"The call for our first Phd position in the lab is now online. If you would like to work on the perception of causality over the next few years, please apply by 14 FEB 2024. See https://mindinaction.github.io/author/open-phd-position/ and https://haushalt-und-personal.hu-berlin.de/de/personal/stellenausschreibungen/wiss-mitarbeiter-in-m-w-d-mit-vorauss-3-4-teilzeitbeschaeftigung-e-13-tv-l-hu-drittmittelfinanzierung-befristet-fuer-3-jahre for more information.\n","tags":null,"title":"Call for PhD position","type":"post"},{"authors":null,"categories":null,"content":"We have a website. If you are interested in studying the interplay between actions and memory, or the perception of causality, please consider joining the lab in Berlin. Watch this space for new positions over the next couple of months.\nI will be more than happy to discuss possibilities for you to join us.\n","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"74cc2cb59c4f00eeb42ad2c0e52e62ba","permalink":"https://mindinaction.github.io/post/24-01-01-the-website/","publishdate":"2024-01-01T00:00:00Z","relpermalink":"/post/24-01-01-the-website/","section":"post","summary":"We have a website. If you are interested in studying the interplay between actions and memory, or the perception of causality, please consider joining the lab in Berlin. Watch this space for new positions over the next couple of months.\n","tags":null,"title":"Launch of the lab website","type":"post"},{"authors":["Ohl","Kroell","Rolfs"],"categories":null,"content":"","date":1704067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1704067200,"objectID":"a5f4ec203d47803cfa525b1257fb0d7e","permalink":"https://mindinaction.github.io/publication/ohl.jepgen.2023/","publishdate":"2024-01-01T00:00:00Z","relpermalink":"/publication/ohl.jepgen.2023/","section":"publication","summary":"Visual working memory and actions are closely intertwined. Memory can guide our actions, but actions also impact what we remember. Even during memory maintenance, actions such as saccadic eye movements select content in visual working memory, resulting in better memory at locations that are congruent with the action goal as compared to incongruent locations. Here, we further substantiate the claim that saccadic eye movements are fundamentally linked to visual working memory by analyzing a large data set (\u003e 100k trials) of nine experiments (eight of them previously published). Using Bayesian hierarchical models, we demonstrate robust saccadic selection across the full range of probed saccade directions, manifesting as better memory performance at the saccade goal irrespective of its location in the visual field. By inspecting individual differences in saccadic selection, we show that saccadic selection was highly prevalent in the population. Moreover, both saccade metrics and visual working memory performance varied considerably across the visual field. Crucially, however, both idiosyncratic and systematic visual field anisotropies were not correlated between visual working memory and the oculomotor system, suggesting that they resulted from different sources (e.g., rely on separate spatial maps). In stark contrast, trial-by-trial variations in saccade metrics were strongly associated with memory performance. At any given location, shorter saccade latencies and more accurate saccades were associated with better memory performance, undergirding a robust link between action selection and visual memory.","tags":null,"title":"Saccadic selection in visual working memory is robust across the visual field and linked to saccade metrics: Evidence from nine experiments and more than 100,000 trials","type":"publication"},{"authors":null,"categories":null,"content":"This is the playground to test local changes.\nAnd implement different settings.\n","date":1700438400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700438400,"objectID":"585b8144115c5f114269f912f3443988","permalink":"https://mindinaction.github.io/extra/","publishdate":"2023-11-20T00:00:00Z","relpermalink":"/extra/","section":"","summary":"This is the playground to test local changes.\n","tags":null,"title":"Playground","type":"page"},{"authors":["Klotzsche","Gaebler","Villringer","Sommer","Nikulin","Ohl"],"categories":null,"content":"","date":1688256000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688256000,"objectID":"771741aaf7f3ade7e813fd00134e18a5","permalink":"https://mindinaction.github.io/publication/klotzsche.psychophys.2023/","publishdate":"2023-07-02T00:00:00Z","relpermalink":"/publication/klotzsche.psychophys.2023/","section":"publication","summary":"Virtual reality (VR) offers a powerful tool for investigating cognitive processes, as it allows researchers to gauge behaviors and mental states in complex, yet highly controlled, scenarios. The use of VR head-mounted displays in combination with physiological measures such as EEG presents new challenges and raises the question whether established findings also generalize to a VR setup. Here, we used a VR headset to assess the spatial constraints underlying two well-established EEG correlates of visual short-term memory:the amplitude of the contralateral delay activity (CDA) and the lateralization of induced alpha power during memory retention. We tested observers' visual memory in a change detection task with bilateral stimulus arrays of either two or four items while varying the horizontal eccentricity of the memory arrays (4, 9, or 14 degrees of visual angle). The CDA amplitude differed between high and low memory load at the two smaller eccentricities, but not at the largest eccentricity. Neither memory load nor eccentricity significantly influenced the observed alpha lateralization. We further fitted time-resolved spatial filters to decode memory load from the event-related potential as well as from its time-frequency decomposition. Classification performance during the retention interval was above-chance level for both approaches and did not vary significantly across eccentricities. We conclude that commercial VR hardware can be utilized to study the CDA and lateralized alpha power, and we provide caveats for future studies targeting these EEG markers of visual memory in a VR setup.","tags":null,"title":"Visual short-term memory-related EEG components in a virtual reality setup","type":"publication"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://mindinaction.github.io/contact/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/contact/","section":"","summary":"","tags":null,"title":"Contact","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://mindinaction.github.io/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"b0d61e5cbb7472bf320bf0ef2aaeb977","permalink":"https://mindinaction.github.io/tour/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/tour/","section":"","summary":"","tags":null,"title":"Tour","type":"landing"},{"authors":["Rolfs","Ohl"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"55c582d77ef8655b30f7bf67b85ecbb0","permalink":"https://mindinaction.github.io/publication/rolfs.bbs.2021/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/rolfs.bbs.2021/","section":"publication","summary":"In active agents, sensory and motor processes form an inevitable bond. This wedding is particularly striking for saccadic eye movements—the prime target of Shadmehr and Ahmed’s thesis—which impose frequent changes on the retinal image. Changes in movement vigor (latency and speed), therefore, will need to be accompanied by changes in visual and attentional processes. We argue that the mechanisms that control movement vigor may also enable vision to attune to changes in movement kinematics.","tags":null,"title":"Moving fast and seeing slow? The perceptual consequences of vigorous movement","type":"publication"},{"authors":["Heuer","Ohl","Rolfs"],"categories":null,"content":"","date":1588032000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588032000,"objectID":"23815f73894cd7120296d2bf3c426688","permalink":"https://mindinaction.github.io/publication/heuer.viscog.2020/","publishdate":"2020-04-28T00:00:00Z","relpermalink":"/publication/heuer.viscog.2020/","section":"publication","summary":"Perception is shaped by actions, which determine the allocation of selective attention across the visual field. Here, we review evidence that maintenance in visual working memory is similarly influenced by actions (eye or hand movements), planned and executed well after encoding. Representations that are relevant for an upcoming action – because they spatially correspond to the action goal or because they are defined along action-related feature dimensions – are automatically prioritised over action-irrelevant representations and held in a stable state. We summarise what is known about specific characteristics and mechanisms of selection-for-action in working memory, such as its temporal dynamics and spatial specificity, and delineate open questions. This newly-burgeoning area of research promotes a more functional perspective on visual working memory that emphasizes its role in action control.","tags":null,"title":"Memory for action: A functional view of selection in visual working memory","type":"publication"},{"authors":["Ohl","Rolfs"],"categories":null,"content":"","date":1581724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581724800,"objectID":"bfef6cbe87750117dd8be98fe2999baf","permalink":"https://mindinaction.github.io/publication/ohl.jvis.2020/","publishdate":"2020-02-15T00:00:00Z","relpermalink":"/publication/ohl.jvis.2020/","section":"publication","summary":"Selection for visual short-term memory (vstm) provides a basis for many cognitive functions. Saccadic eye movements sway this selection in favor of stimuli previously seen at locations congruent with their target. In three experiments, we provide converging evidence that this saccadic selection is implemented as a fundamental, inevitable selection process, rather than a top-down strategy. In particular, benefits for congruent over incongruent items were largely constant across set sizes ranging from two to eight items (Experiment 1), showing that saccadic selection imposes priorities on vstm irrespective of memory load and is effective even when only few representations need to be maintained. Moreover, a decrement in performance for incongruent items occurred reliably, whether the congruent location contained a task-relevant item or an irrelevant noise patch (Experiment 2). Finally, saccadic selection was immune to a strong manipulation of the observer's attentional priorities (Experiment 3). Given the prevalence of saccades in natural vision, our results demonstrate a fundamental and ecologically relevant selection mechanism for vstm. Saccades systematically eliminate information seen at non-target locations, while information at the saccade target remains available to recall. This simple heuristic is effective in the absence of informative cues and may incapacitate voluntary selection mechanisms that are incongruent with ongoing movement plans.","tags":null,"title":"Bold moves: Inevitable saccadic selection in visual short-term memory","type":"publication"},{"authors":["Kunzendorf","Klotzsche","Akbal","Villringer","Ohl","Gaebler"],"categories":null,"content":"","date":1564617600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564617600,"objectID":"fa5545e5480b3554eba132c6e0900629","permalink":"https://mindinaction.github.io/publication/kunzendorf.psychophys.2019/","publishdate":"2019-08-01T00:00:00Z","relpermalink":"/publication/kunzendorf.psychophys.2019/","section":"publication","summary":"Perception and cognition oscillate with fluctuating bodily states. For example, visual processing has been shown to change with alternating cardiac phases. Here, we study the heartbeat’s role for active information sampling—testing whether humans implicitly act upon their environment so that relevant signals appear during preferred cardiac phases. During the encoding period of a visual memory experiment, participants clicked through a set of emotional pictures to memorize them for a later recognition test. By self-paced key press, they actively prompted the onset of short (100 ms) presented pictures. Simultaneously recorded electrocardiograms allowed us to analyze the self-initiated picture onsets relative to the heartbeat. We find that self-initiated picture onsets vary across the cardiac cycle, showing an increase during cardiac systole, while memory performance was not affected by the heartbeat. We conclude that active information sampling integrates heart-related signals, thereby extending previous findings on the association between body-brain interactions and behavior.","tags":null,"title":"Active information sampling varies across the cardiac cycle","type":"publication"},{"authors":["Ohl","Rolfs"],"categories":null,"content":"","date":1530662400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530662400,"objectID":"92dfb64387e229bf33f768d1d9963347","permalink":"https://mindinaction.github.io/publication/ohl.concog.2018/","publishdate":"2018-07-04T00:00:00Z","relpermalink":"/publication/ohl.concog.2018/","section":"publication","summary":"Saccadic eye movements prioritize the memory of visual stimuli that had previously been seen at the saccade target. In two experiments, we assessed whether this influence is limited to fragile memory traces or if saccades can also affect consolidated representations in visuospatial working memory (VSWM). To interfere with fragile memory traces, we presented visual masks at different delays following the offset of a memory array and simultaneously prompted participants to generate a saccade to one location. Masking was very effective. Memory performance was lowest right after the disappearance of the memory array and gradually increased for later mask onsets. In spite of that, memory was best for stimuli congruent with the saccade target. This advantage was largest at shortest delays and then decreased over the course of a second. Insofar as only consolidated representations survive interference from masks, we conclude that saccades exert spatially selective biases on stable representations in VSWM.","tags":null,"title":"Saccadic selection of stabilized items in visuospatial working memory","type":"publication"},{"authors":["Ohl","Kuper","Rolfs"],"categories":null,"content":"","date":1510704000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1510704000,"objectID":"94e31577a82106be4d3ba6919cb5b8ba","permalink":"https://mindinaction.github.io/publication/ohl.jvis.2017/","publishdate":"2017-11-15T00:00:00Z","relpermalink":"/publication/ohl.jvis.2017/","section":"publication","summary":"Saccadic eye movements cause a rapid sweep of the visual image across the retina and bring the saccade's target into high-acuity foveal vision. Even before saccade onset, visual processing is selectively prioritized at the saccade target. To determine how this presaccadic attention shift exerts its influence on visual selection, we compare the dynamics of perceptual tuning curves before movement onset at the saccade target and in the opposite hemifield. Participants monitored a 30-Hz sequence of randomly oriented gratings for a target orientation. Combining a reverse correlation technique previously used to study orientation tuning in neurons and general additive mixed modeling, we found that perceptual reports were tuned to the target orientation. The gain of orientation tuning increased markedly within the last 100 ms before saccade onset. In addition, we observed finer orientation tuning right before saccade onset. This increase in gain and tuning occurred at the saccade target location and was not observed at the incongruent location in the opposite hemifield. The present findings suggest, therefore, that presaccadic attention exerts its influence on vision in a spatially and feature-selective manner, enhancing performance and sharpening feature tuning at the future gaze location before the eyes start moving.","tags":null,"title":"Selective enhancement of orientation tuning before saccades","type":"publication"},{"authors":["Ohl","Rolfs"],"categories":null,"content":"","date":1495584000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1495584000,"objectID":"88c70c8462048402c406362f9d7ee106","permalink":"https://mindinaction.github.io/publication/ohl.bbs.2017/","publishdate":"2017-05-24T00:00:00Z","relpermalink":"/publication/ohl.bbs.2017/","section":"publication","summary":"Using fixations as the fundamental unit of visual search is an appealing gear change in a paradigm that has long dominated attention research. To truly inform theories of search, however, additional challenges must be faced, including (1) an empirically motivated definition of fixation in the presence of fixational saccades and (2) the biases and limitations of transsaccadic perception and memory.","tags":null,"title":"Chances and challenges for an active visual search perspective","type":"publication"},{"authors":["Ohl","Rolfs"],"categories":null,"content":"","date":1494806400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494806400,"objectID":"bd7a8497c0c7478e0878ed972a82349c","permalink":"https://mindinaction.github.io/publication/ohl.jeplmc.2017/","publishdate":"2017-05-15T00:00:00Z","relpermalink":"/publication/ohl.jeplmc.2017/","section":"publication","summary":"Visual short-term memory (VSTM) is a crucial repository of information when events unfold rapidly before our eyes, yet it maintains only a fraction of the sensory information encoded by the visual system. Here, we tested the hypothesis that saccadic eye movements provide a natural bottleneck for the transition of fragile content in sensory memory to VSTM. In 4 experiments, we show that saccades, planned and executed after the disappearance of a memory array, markedly bias visual memory performance. First, items that had appeared at the saccade target were more readily remembered than items that had appeared elsewhere, even though the saccade was irrelevant to the memory task (Experiment 1). Second, this influence was strongest for saccades elicited right after the disappearance of the memory array and gradually declined over the course of a second (Experiment 2). Third, the saccade stabilized memory representations. The imposed bias persisted even several seconds after saccade execution (Experiment 3). Finally, the advantage for stimuli congruent with the saccade target occurred even when that stimulus was far less likely to be probed in the memory test than any other stimulus in the array, ruling out a strategic effort of observers to memorize information presented at the saccade target (Experiment 4). Together, these results make a strong case that saccades inadvertently determine the content of VSTM, and highlight the key role of actions for the fundamental building blocks of cognition.","tags":null,"title":"Saccadic eye movements impose a natural bottleneck on visual short-term memory","type":"publication"},{"authors":["Kalogeropoulou","Jagadeesh","Ohl","Rolfs"],"categories":null,"content":"","date":1492214400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492214400,"objectID":"f1cb083593742500a560c6ec9b007f4d","permalink":"https://mindinaction.github.io/publication/kalogeropoulou.pbr.2017/","publishdate":"2017-04-15T00:00:00Z","relpermalink":"/publication/kalogeropoulou.pbr.2017/","section":"publication","summary":"Many everyday tasks require prioritizing some visual features over competing ones, both during the selection from the rich sensory input and while maintaining information in visual short-term memory (VSTM). Here, we show that observers can change priorities in VSTM when, initially, they attended to a different feature. Observers reported from memory the orientation of one of two spatially interspersed groups of black and white gratings. Using colored pre-cues (presented before stimulus onset) and retro-cues (presented after stimulus offset) predicting the to-be-reported group, we manipulated observers’ feature priorities independently during stimulus encoding and maintenance, respectively. Valid pre-cues reliably increased observers’ performance (reduced guessing, increased report precision) as compared to neutral ones; invalid pre-cues had the opposite effect. Valid retro-cues also consistently improved performance (by reducing random guesses), even if the unexpected group suddenly became relevant (invalid-valid condition). Thus, feature-based attention can reshape priorities in VSTM protecting information that would otherwise be forgotten.","tags":null,"title":"Setting and changing feature priorities in Visual Short-Term Memory","type":"publication"},{"authors":["Cassanello","Ohl","Rolfs"],"categories":null,"content":"","date":1470009600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470009600,"objectID":"a91ce5fdcd1283ec04572430f6a87cdc","permalink":"https://mindinaction.github.io/publication/cassanelle.jneurophys.2016/","publishdate":"2016-08-01T00:00:00Z","relpermalink":"/publication/cassanelle.jneurophys.2016/","section":"publication","summary":"Saccadic adaptation maintains the correct mapping between eye movements and their targets, yet the dynamics of saccadic gain changes in the presence of systematically varying disturbances has not been extensively studied. Here we assessed changes in the gain of saccade amplitudes induced by continuous and periodic postsaccadic visual feedback. Observers made saccades following a sequence of target steps either along the horizontal meridian (Two-way adaptation) or with unconstrained saccade directions (Global adaptation). An intrasaccadic step—following a sinusoidal variation as a function of the trial number (with 3 different frequencies tested in separate blocks)—consistently displaced the target along its vector. The oculomotor system responded to the resulting feedback error by modifying saccade amplitudes in a periodic fashion with similar frequency of variation but lagging the disturbance by a few tens of trials. This periodic response was superimposed on a drift toward stronger hypometria with similar asymptotes and decay rates across stimulus conditions. The magnitude of the periodic response decreased with increasing frequency and was smaller and more delayed for Global than Two-way adaptation. These results suggest that—in addition to the well-characterized return-to-baseline response observed in protocols using constant visual feedback—the oculomotor system attempts to minimize the feedback error by integrating its variation across trials. This process resembles a convolution with an internal response function, whose structure would be determined by coefficients of the learning model. Our protocol reveals this fast learning process in single short experimental sessions, qualifying it for the study of sensorimotor learning in health and disease.","tags":null,"title":"Saccadic adaptation to a systematically varying disturbance","type":"publication"},{"authors":["Ohl","Kliegl"],"categories":null,"content":"","date":1468540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1468540800,"objectID":"a3ddfadb32bbf61fd33800a8568edfb3","permalink":"https://mindinaction.github.io/publication/ohl.visres.2016/","publishdate":"2016-07-15T00:00:00Z","relpermalink":"/publication/ohl.visres.2016/","section":"publication","summary":"Saccadic eye movements are frequently followed by smaller secondary saccades which are generally assumed to correct for the error in primary saccade landing position. However, secondary saccades can also occur after accurate primary saccades and they are often as small as microsaccades, therefore raising the need to further scrutinize the processes involved in secondary saccade generation. Following up a previous study, we analyzed secondary saccades using rate analysis which allows us to quantify experimental effects as shifts in distributions, therefore going beyond comparisons of mean differences. We use Aalen’s additive hazards model to delineate the time course of key influences on the secondary saccade rate. In addition to the established effect of primary saccade error, we observed a time-varying influence of under- vs. overshooting – with a higher risk of generating secondary saccades following undershoots. Moreover, increasing target eccentricity influenced the programming of secondary saccades, therefore demonstrating that error-unrelated variables co-determine secondary saccade programs. Our results provide new insights into the generative mechanisms of small saccades during postsaccadic fixation that need to be accounted for by secondary saccade models.","tags":null,"title":"Revealing the time course of signals influencing the generation of secondary saccades using Aalen’s additive hazards model","type":"publication"},{"authors":["Ohl","Wohltat","Kliegl","Pollatos","Engbert"],"categories":null,"content":"","date":1453852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1453852800,"objectID":"a1068f9220dcc77324a89cca12ecb859","permalink":"https://mindinaction.github.io/publication/ohl.jn.2016/","publishdate":"2016-01-27T00:00:00Z","relpermalink":"/publication/ohl.jn.2016/","section":"publication","summary":"During visual fixation, the eye generates microsaccades and slower components of fixational eye movements that are part of the visual processing strategy in humans. Here, we show that ongoing heartbeat is coupled to temporal rate variations in the generation of microsaccades. Using coregistration of eye recording and ECG in humans, we tested the hypothesis that microsaccade onsets are coupled to the relative phase of the R-R intervals in heartbeats. We observed significantly more microsaccades during the early phase after the R peak in the ECG. This form of coupling between heartbeat and eye movements was substantiated by the additional finding of a coupling between heart phase and motion activity in slow fixational eye movements; i.e., retinal image slip caused by physiological drift. Our findings therefore demonstrate a coupling of the oculomotor system and ongoing heartbeat, which provides further evidence for bodily influences on visuomotor functioning.","tags":null,"title":"Microsaccades are coupled to heartbeat","type":"publication"},{"authors":["Ohl","Brandt","Kliegl"],"categories":null,"content":"","date":1365984000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1365984000,"objectID":"cb5c6f16bbe582d7271f8befe647302b","permalink":"https://mindinaction.github.io/publication/ohl.jvis.2013/","publishdate":"2013-04-15T00:00:00Z","relpermalink":"/publication/ohl.jvis.2013/","section":"publication","summary":"Primary saccades are often followed by small secondary saccades, which are generally thought to reduce the distance between the saccade endpoint and target location. Accumulated evidence demonstrates that secondary saccades are subject to various influences, among which retinal feedback during postsaccadic fixation constitutes only one important signal. Recently, we reported that target eccentricity and an orientation bias influence the generation of secondary saccades. In the present study, we examine secondary saccades in the absence of postsaccadic visual feedback. Although extraretinal signals (e.g., efference copy) have received widespread attention in eye-movement studies, it is still unclear whether an extraretinal error signal contributes to the programming of secondary saccades. We have observed that secondary saccade latency and amplitude depend on primary saccade error despite the absence of postsaccadic visual feedback. Strong evidence for an extraretinal error signal influencing secondary saccade programming is given by the observation that secondary saccades are more likely to be oriented in a direction opposite to the primary saccade as primary saccade error shifts from target undershoot to overshoot. We further show how the functional relationship between primary saccade landing position and secondary saccade characteristics varies as a function of target eccentricity. We propose that initial target eccentricity and an extraretinal error signal codetermine the postsaccadic activity distribution in the saccadic motor map when no visual feedback is available.","tags":null,"title":"The generation of secondary saccades without postsaccadic visual feedback","type":"publication"}]