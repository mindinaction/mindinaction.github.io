<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MIAlab</title>
    <link>https://mindinaction.github.io/</link>
      <atom:link href="https://mindinaction.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>MIAlab</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://mindinaction.github.io/media/icon_hub4dcace8ce2798ac95f15b515349aeea_1784_512x512_fill_lanczos_center_3.png</url>
      <title>MIAlab</title>
      <link>https://mindinaction.github.io/</link>
    </image>
    
    <item>
      <title>Example Event</title>
      <link>https://mindinaction.github.io/event/example/</link>
      <pubDate>Sat, 01 Jun 2030 13:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/event/example/</guid>
      <description>&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Wowchemy&amp;rsquo;s &lt;a href=&#34;https://wowchemy.com/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;em&gt;Slides&lt;/em&gt;&lt;/a&gt; feature and link using &lt;code&gt;slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://wowchemy.com/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Further event details, including page elements such as image galleries, can be added to the body of this page.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Putting causality into context: Causal capture escapes the visual adaptation of causality</title>
      <link>https://mindinaction.github.io/publication/sro.2025/</link>
      <pubDate>Sun, 21 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/sro.2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>In pursuit of saccade awareness: Limited control and minimal conscious access to catch-up saccades during smooth pursuit eye movements</title>
      <link>https://mindinaction.github.io/publication/klanke.2025c/</link>
      <pubDate>Sat, 20 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/klanke.2025c/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Microsaccades do not give rise to a conscious feeling of agency for their sensorimotor consequences in visual perception</title>
      <link>https://mindinaction.github.io/publication/klanke.2025b/</link>
      <pubDate>Fri, 19 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/klanke.2025b/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Summer comes to an end</title>
      <link>https://mindinaction.github.io/post/25-09-16-summerend/</link>
      <pubDate>Tue, 16 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/25-09-16-summerend/</guid>
      <description>&lt;p&gt;An exciting science summer is coming to an end. Laura presented her current experiments at the summer school in Tübingen and deepened her knowledge of statistics at the summer school “Statistical Methods for Linguistics and Psychology” in Potsdam. Inchara presented her work on ensemble perception at ECVP in Mainz while Ben had the chance to learn more about visual perception at a summer school in Pisa.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>New paper in Nature Communications and press release</title>
      <link>https://mindinaction.github.io/post/25-05-08-natcomm/</link>
      <pubDate>Thu, 08 May 2025 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/25-05-08-natcomm/</guid>
      <description>&lt;p&gt;This paper on the visibility of saccade-like motion has been long in the making and is finally out. In a tour de force this paper shows that the perceptual thresholds for high-speed motion perception during fixation can be predicted based on the lawful kinematics of saccadic eye movements. Check out the paper just published in Nature Communications &lt;a href=&#34;https://www.nature.com/articles/s41467-025-58659-9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.nature.com/articles/s41467-025-58659-9&lt;/a&gt; and the press release &lt;a href=&#34;https://www.scienceofintelligence.de/too-fast-to-see-eye-movements-predict-speed-limits-in-perception/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.scienceofintelligence.de/too-fast-to-see-eye-movements-predict-speed-limits-in-perception/&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sensorimotor awareness requires intention: Evidence from minuscule eye movements</title>
      <link>https://mindinaction.github.io/publication/klanke.2025a/</link>
      <pubDate>Sun, 04 May 2025 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/klanke.2025a/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Joint retreat of rolfslab and mialab</title>
      <link>https://mindinaction.github.io/post/25-04-17-retreat/</link>
      <pubDate>Thu, 17 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/25-04-17-retreat/</guid>
      <description>&lt;p&gt;We have been to our first retreat in beautiful Forsthaus Tornow with good science, delicious food from great cooking teams, time to talk and lots of fun with a great group of people. [featured photo by Wiebke]&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-group-picture-of-rolfslab-and-mialab-photo-by-caro&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /post/25-04-17-retreat/image1_huc6735c379a1007320dc193ed6c1dd334_1825023_7a859016f8fce8ed5a403bb709e76ac2.webp 400w,
               /post/25-04-17-retreat/image1_huc6735c379a1007320dc193ed6c1dd334_1825023_3f7a4eecd399f4f3695fd1b0eadb2935.webp 760w,
               /post/25-04-17-retreat/image1_huc6735c379a1007320dc193ed6c1dd334_1825023_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://mindinaction.github.io/post/25-04-17-retreat/image1_huc6735c379a1007320dc193ed6c1dd334_1825023_7a859016f8fce8ed5a403bb709e76ac2.webp&#34;
               width=&#34;570&#34;
               height=&#34;760&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      group picture of rolfslab and mialab [photo by Caro]
    &lt;/figcaption&gt;&lt;/figure&gt;

















&lt;figure  id=&#34;figure-mentoring-walk-photo-by-inchara&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /post/25-04-17-retreat/image2_hu21d3d07b5bb3e2d5d0810ed4adbc5776_383041_b47b6a7ee20cf9b5a0a24dd6be0152f4.webp 400w,
               /post/25-04-17-retreat/image2_hu21d3d07b5bb3e2d5d0810ed4adbc5776_383041_396aa4e9d7e5a1b19e4be4e5e60b694a.webp 760w,
               /post/25-04-17-retreat/image2_hu21d3d07b5bb3e2d5d0810ed4adbc5776_383041_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://mindinaction.github.io/post/25-04-17-retreat/image2_hu21d3d07b5bb3e2d5d0810ed4adbc5776_383041_b47b6a7ee20cf9b5a0a24dd6be0152f4.webp&#34;
               width=&#34;760&#34;
               height=&#34;570&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      mentoring walk [photo by Inchara]
    &lt;/figcaption&gt;&lt;/figure&gt;

















&lt;figure  id=&#34;figure-the-retreat-location-photo-by-siri&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;screen reader text&#34; srcset=&#34;
               /post/25-04-17-retreat/image3_hub7767da4032c6540a65824e723c469af_3639239_aca11c4188d3377307d17905567ac0e7.webp 400w,
               /post/25-04-17-retreat/image3_hub7767da4032c6540a65824e723c469af_3639239_2392875a79828fc1c01ab37a6601cbd1.webp 760w,
               /post/25-04-17-retreat/image3_hub7767da4032c6540a65824e723c469af_3639239_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://mindinaction.github.io/post/25-04-17-retreat/image3_hub7767da4032c6540a65824e723c469af_3639239_aca11c4188d3377307d17905567ac0e7.webp&#34;
               width=&#34;760&#34;
               height=&#34;428&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      the retreat location [photo by Siri]
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>New preprint on causal capture</title>
      <link>https://mindinaction.github.io/post/25-04-10-preprint-capture/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/25-04-10-preprint-capture/</guid>
      <description>&lt;p&gt;Ben, Martin and Sven have a new preprint on causal capture. In their study, they pitted visual adaptation against contextual influences on causal perception and found that contextual influences escaped the strong influence of visual adaptation. Congratulations to Ben for submitting his first manuscript. For more information, see &lt;a href=&#34;https://www.biorxiv.org/content/10.1101/2025.04.10.648104v1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.biorxiv.org/content/10.1101/2025.04.10.648104v1&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Lawful kinematics link eye movements to the limits of high-speed perception</title>
      <link>https://mindinaction.github.io/publication/rolfs.natcomm.2025/</link>
      <pubDate>Tue, 08 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/rolfs.natcomm.2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>New paper in eLife on the perception of causality</title>
      <link>https://mindinaction.github.io/post/25-04-03-paper-elife/</link>
      <pubDate>Fri, 04 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/25-04-03-paper-elife/</guid>
      <description>&lt;p&gt;Sven and Martin published their paper on the directional tuning of the perception of causality at eLife. For more details see &lt;a href=&#34;https://doi.org/10.7554/eLife.93454.3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.7554/eLife.93454.3&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Visual routines for detecting causal interactions are tuned to motion direction</title>
      <link>https://mindinaction.github.io/publication/ohl.elife.2025/</link>
      <pubDate>Thu, 03 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/ohl.elife.2025/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MIAlab at TeaP in Frankfurt</title>
      <link>https://mindinaction.github.io/post/25-03-05-teap/</link>
      <pubDate>Wed, 05 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/25-03-05-teap/</guid>
      <description>&lt;p&gt;The MIAlab is on the way to its first conference. We will be represented in Frankfurt at the TeaP with two posters and a talk. Get in touch with us if you are interested in the perception of causality or want to hear more about the influence of saccadic eye movements on visual memory.&lt;/p&gt;
&lt;p&gt;Our slots:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;11 March at 3:00 pm&lt;/strong&gt; &lt;br&gt;
The Spatial Specificity and Recovery of Visual Adaptation in Causal Perception (Poster by Laura)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;12 March at 8:30 am&lt;/strong&gt; &lt;br&gt;
Saccadic selection in vision and memory (Talk by Sven)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;12 March at 3:00 pm&lt;/strong&gt; &lt;br&gt;
Context events bypass the influence of visual adaptation on the perception of causality (Poster by Ben)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Demos</title>
      <link>https://mindinaction.github.io/demos/</link>
      <pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/demos/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Inchara joins rolfslab and mialab</title>
      <link>https://mindinaction.github.io/post/24-10-15-october/</link>
      <pubDate>Tue, 15 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/24-10-15-october/</guid>
      <description>&lt;p&gt;I am so happy to welcome Inchara to Berlin. She received a scholarship from the Berlin School of Mind and Brain to pursue her PhD on the interplay between actions, perception and memory.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>September outlook</title>
      <link>https://mindinaction.github.io/post/24-09-15-september/</link>
      <pubDate>Sun, 15 Sep 2024 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/24-09-15-september/</guid>
      <description>&lt;p&gt;If you divide the lab year roughly into presenting science vs. creating science, then September is the month when we all come back to our labs and get busy tinkering, implementing and piloting new ideas. We&amp;rsquo;ve spent the last few weeks doing just that and are still getting new input through our regular Reading Club, which everyone actively attends. Our team is now almost complete for the next few months (but wait for the next post) and I am happy to work with such a wonderful team that is highly motivated to do good science.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Welcome to the lab Laura</title>
      <link>https://mindinaction.github.io/post/24-08-01-laura/</link>
      <pubDate>Thu, 01 Aug 2024 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/24-08-01-laura/</guid>
      <description>&lt;p&gt;We are very happy to welcome Laura van Zantwijk as a new PhD student in the MIAlab. Laura did her Master in Utrecht and has already contributed to many successful research projects on active perception. Welcome to Berlin Laura. We are so happy to have you here.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Workshop on causality and spatial relations in Berlin</title>
      <link>https://mindinaction.github.io/post/24-07-22-ripe/</link>
      <pubDate>Mon, 22 Jul 2024 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/24-07-22-ripe/</guid>
      <description>&lt;p&gt;We participated at the spontaneous RIPE workshop in Berlin. What a great opportunity to learn more about relations from so many smart people. Hopefully, this workshop will take place again next year.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>New preprint on sensorimotor awareness</title>
      <link>https://mindinaction.github.io/post/24-07-03-preprintjan/</link>
      <pubDate>Wed, 15 May 2024 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/24-07-03-preprintjan/</guid>
      <description>&lt;p&gt;I am so incredibly happy that this preprint on sensorimotor awareness with Jan Klanke as first author is available on biorxiv. Jan has created a wonderful new paradigm to measure microsaccade sensitivity. There are so many exciting methodological finesses in the study that together highlight the role of intention in sensorimotor awareness. See more here &lt;a href=&#34;https://doi.org/10.1101/2024.07.02.601661&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://doi.org/10.1101/2024.07.02.601661&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The MIAlab at VSS</title>
      <link>https://mindinaction.github.io/post/24-05-15-vss/</link>
      <pubDate>Wed, 15 May 2024 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/24-05-15-vss/</guid>
      <description>&lt;p&gt;One of the annual highlights in our research calendar is just around the corner. The MIAlab is flying to VSS. Sven will be giving a talk on Saturday with the title &amp;ldquo;What Newton did not know about Newton&amp;rsquo;s cradle: Separating visual routines for cause and effect&amp;rdquo; in the talk session &amp;ldquo;Perception of Relations, Intuitive Physics.&amp;rdquo; A lot of other cool talks are in the same session and we are very excited.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Welcome to Siri in the MIAlab</title>
      <link>https://mindinaction.github.io/post/24-05-01-siri/</link>
      <pubDate>Wed, 01 May 2024 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/24-05-01-siri/</guid>
      <description>&lt;p&gt;We are delighted that Siri is now starting as a student assistant in the lab. She will be a great help to us in collecting data and we are already looking forward to programming new stimuli together with her. Siri is now officially the first lab member in our still young lab. Welcome Siri!&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Lab visit in Oxford</title>
      <link>https://mindinaction.github.io/post/24-02-01-oxford/</link>
      <pubDate>Mon, 19 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/24-02-01-oxford/</guid>
      <description>&lt;p&gt;We were in Oxford for a few days after being invited by Dejan Draschkow and his lab for a workshop on combining eye tracking and EEG in virtual reality. Felix Klotzsche gave a wonderful introduction, motivating but also highlighting some important considerations when using VR as a tool for cognitive neuroscience. On the last day, we had the pleasure of presenting our memory studies using eye movements, EEG and VR at the BEACON seminar. Thanks to our host we had the best time in Oxford.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Apply as a student research assistant</title>
      <link>https://mindinaction.github.io/post/24-02-01-call-for-shk/</link>
      <pubDate>Thu, 01 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/24-02-01-call-for-shk/</guid>
      <description>&lt;p&gt;If you are currently enrolled as a student and would like to work in our laboratory in Berlin, then this job may be of interest to you. You will support us in collecting data for psychophysical experiments and gain insights into our day-to-day research work. If this sounds interesting, please apply by 14 February.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Call for PhD position</title>
      <link>https://mindinaction.github.io/post/24-01-17-call-for-phd-position/</link>
      <pubDate>Wed, 17 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/24-01-17-call-for-phd-position/</guid>
      <description>&lt;p&gt;The call for our first Phd position in the lab is now online. If you would like to work on the perception of causality over the next few years, please apply by 14 FEB 2024. See &lt;a href=&#34;https://mindinaction.github.io/author/open-phd-position/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://mindinaction.github.io/author/open-phd-position/&lt;/a&gt; and &lt;a href=&#34;https://haushalt-und-personal.hu-berlin.de/de/personal/stellenausschreibungen/wiss-mitarbeiter-in-m-w-d-mit-vorauss-3-4-teilzeitbeschaeftigung-e-13-tv-l-hu-drittmittelfinanzierung-befristet-fuer-3-jahre&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://haushalt-und-personal.hu-berlin.de/de/personal/stellenausschreibungen/wiss-mitarbeiter-in-m-w-d-mit-vorauss-3-4-teilzeitbeschaeftigung-e-13-tv-l-hu-drittmittelfinanzierung-befristet-fuer-3-jahre&lt;/a&gt; for more information.&lt;/p&gt;
&lt;p&gt;When applying, please refer to the number DR/023/24 in your application. I am looking forward to meeting you.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Launch of the lab website</title>
      <link>https://mindinaction.github.io/post/24-01-01-the-website/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/post/24-01-01-the-website/</guid>
      <description>&lt;p&gt;We have a website. If you are interested in studying the interplay between actions and memory, or the perception of causality, please consider joining the lab in Berlin. Watch this space for new positions over the next couple of months.&lt;/p&gt;
&lt;p&gt;I will be more than happy to discuss possibilities for you to join us.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Saccadic selection in visual working memory is robust across the visual field and linked to saccade metrics: Evidence from nine experiments and more than 100,000 trials</title>
      <link>https://mindinaction.github.io/publication/ohl.jepgen.2023/</link>
      <pubDate>Mon, 01 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/ohl.jepgen.2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Playground</title>
      <link>https://mindinaction.github.io/extra/</link>
      <pubDate>Mon, 20 Nov 2023 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/extra/</guid>
      <description>&lt;p&gt;This is the playground to test local changes.&lt;/p&gt;
&lt;p&gt;And implement different settings.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Visual short-term memory-related EEG components in a virtual reality setup</title>
      <link>https://mindinaction.github.io/publication/klotzsche.psychophys.2023/</link>
      <pubDate>Sun, 02 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/klotzsche.psychophys.2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>https://mindinaction.github.io/contact/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title>People</title>
      <link>https://mindinaction.github.io/people/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/people/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Tour</title>
      <link>https://mindinaction.github.io/tour/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/tour/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Moving fast and seeing slow? The perceptual consequences of vigorous movement</title>
      <link>https://mindinaction.github.io/publication/rolfs.bbs.2021/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/rolfs.bbs.2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Memory for action: A functional view of selection in visual working memory</title>
      <link>https://mindinaction.github.io/publication/heuer.viscog.2020/</link>
      <pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/heuer.viscog.2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bold moves: Inevitable saccadic selection in visual short-term memory</title>
      <link>https://mindinaction.github.io/publication/ohl.jvis.2020/</link>
      <pubDate>Sat, 15 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/ohl.jvis.2020/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Active information sampling varies across the cardiac cycle</title>
      <link>https://mindinaction.github.io/publication/kunzendorf.psychophys.2019/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/kunzendorf.psychophys.2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Saccadic selection of stabilized items in visuospatial working memory</title>
      <link>https://mindinaction.github.io/publication/ohl.concog.2018/</link>
      <pubDate>Wed, 04 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/ohl.concog.2018/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Selective enhancement of orientation tuning before saccades</title>
      <link>https://mindinaction.github.io/publication/ohl.jvis.2017/</link>
      <pubDate>Wed, 15 Nov 2017 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/ohl.jvis.2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Chances and challenges for an active visual search perspective</title>
      <link>https://mindinaction.github.io/publication/ohl.bbs.2017/</link>
      <pubDate>Wed, 24 May 2017 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/ohl.bbs.2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Saccadic eye movements impose a natural bottleneck on visual short-term memory</title>
      <link>https://mindinaction.github.io/publication/ohl.jeplmc.2017/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/ohl.jeplmc.2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Setting and changing feature priorities in Visual Short-Term Memory</title>
      <link>https://mindinaction.github.io/publication/kalogeropoulou.pbr.2017/</link>
      <pubDate>Sat, 15 Apr 2017 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/kalogeropoulou.pbr.2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Saccadic adaptation to a systematically varying disturbance</title>
      <link>https://mindinaction.github.io/publication/cassanelle.jneurophys.2016/</link>
      <pubDate>Mon, 01 Aug 2016 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/cassanelle.jneurophys.2016/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Revealing the time course of signals influencing the generation of secondary saccades using Aalen’s additive hazards model</title>
      <link>https://mindinaction.github.io/publication/ohl.visres.2016/</link>
      <pubDate>Fri, 15 Jul 2016 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/ohl.visres.2016/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Microsaccades are coupled to heartbeat</title>
      <link>https://mindinaction.github.io/publication/ohl.jn.2016/</link>
      <pubDate>Wed, 27 Jan 2016 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/ohl.jn.2016/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The generation of secondary saccades without postsaccadic visual feedback</title>
      <link>https://mindinaction.github.io/publication/ohl.jvis.2013/</link>
      <pubDate>Mon, 15 Apr 2013 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/publication/ohl.jvis.2013/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://mindinaction.github.io/admin/config.yml</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://mindinaction.github.io/admin/config.yml</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
